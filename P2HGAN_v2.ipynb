{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of defining composite models for training cyclegan generators\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.models import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import Activation\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.layers import Concatenate\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "from matplotlib import image\n",
    "import numpy as np\n",
    "from numpy import ones\n",
    "from numpy import zeros\n",
    "\n",
    "# define the discriminator model\n",
    "def define_discriminator(image_shape):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# source image input\n",
    "\tin_image = Input(shape=image_shape)\n",
    "\tnfilters = 32\n",
    "\tkernel_size = 4\n",
    "\t# C64\n",
    "\td = Conv2D(nfilters, kernel_size, strides=(2,2), padding='same', kernel_initializer=init)(in_image)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# C128\n",
    "\td = Conv2D(nfilters*2, kernel_size, strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "\td = InstanceNormalization(axis=-1)(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# C256\n",
    "\td = Conv2D(nfilters*4, kernel_size, strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "\td = InstanceNormalization(axis=-1)(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# C512\n",
    "\td = Conv2D(nfilters*8, kernel_size, strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "\td = InstanceNormalization(axis=-1)(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# second last output layer\n",
    "\td = Conv2D(nfilters*8, kernel_size, padding='same', kernel_initializer=init)(d)\n",
    "\td = InstanceNormalization(axis=-1)(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# patch output\n",
    "\tpatch_out = Conv2D(1, kernel_size, padding='same', kernel_initializer=init)(d)\n",
    "\t# define model\n",
    "\tmodel = Model(in_image, patch_out)\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='mse', optimizer=Adam(lr=0.0002, beta_1=0.5), loss_weights=[0.5])\n",
    "\treturn model\n",
    "\n",
    "# generator a resnet block\n",
    "def resnet_block(n_filters, input_layer):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# first layer convolutional layer\n",
    "\tg = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(input_layer)\n",
    "\tg = InstanceNormalization(axis=-1)(g)\n",
    "\tg = Activation('relu')(g)\n",
    "\t# second convolutional layer\n",
    "\tg = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(g)\n",
    "\tg = InstanceNormalization(axis=-1)(g)\n",
    "\t# concatenate merge channel-wise with input layer\n",
    "\tg = Concatenate()([g, input_layer])\n",
    "\treturn g\n",
    "\n",
    "# define the standalone generator model\n",
    "def define_generator(image_shape, n_resnet=9):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# image input\n",
    "\tin_image = Input(shape=image_shape)\n",
    "\tn_filters = 32\n",
    "\tkernel_size = 3\n",
    "\t# c7s1-64\n",
    "\tg = Conv2D(n_filters, (7,7), padding='same', kernel_initializer=init)(in_image)\n",
    "\tg = InstanceNormalization(axis=-1)(g)\n",
    "\tg = Activation('relu')(g)\n",
    "\t# d128\n",
    "\tg = Conv2D(n_filters*2, kernel_size, strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
    "\tg = InstanceNormalization(axis=-1)(g)\n",
    "\tg = Activation('relu')(g)\n",
    "\t# d256\n",
    "\tg = Conv2D(n_filters*4, kernel_size, strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
    "\tg = InstanceNormalization(axis=-1)(g)\n",
    "\tg = Activation('relu')(g)\n",
    "\t# R256\n",
    "\tfor _ in range(n_resnet):\n",
    "\t\tg = resnet_block(n_filters*4, g)\n",
    "\t# u128\n",
    "\tg = Conv2DTranspose(n_filters*2, kernel_size, strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
    "\tg = InstanceNormalization(axis=-1)(g)\n",
    "\tg = Activation('relu')(g)\n",
    "\t# u64\n",
    "\tg = Conv2DTranspose(n_filters, kernel_size, strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
    "\tg = InstanceNormalization(axis=-1)(g)\n",
    "\tg = Activation('relu')(g)\n",
    "\t# c7s1-3\n",
    "\tg = Conv2D(1, (7,7), padding='same', kernel_initializer=init)(g)\n",
    "\tg = InstanceNormalization(axis=-1)(g)\n",
    "\tout_image = Activation('tanh')(g)\n",
    "\t# define model\n",
    "\tmodel = Model(in_image, out_image)\n",
    "\treturn model\n",
    "\n",
    "# define a composite model for updating generators by adversarial and cycle loss\n",
    "def define_composite_model(g_model_1, d_model, g_model_2, image_shape):\n",
    "\t# ensure the model we're updating is trainable\n",
    "\tg_model_1.trainable = True\n",
    "\t# mark discriminator as not trainable\n",
    "\td_model.trainable = False\n",
    "\t# mark other generator model as not trainable\n",
    "\tg_model_2.trainable = False\n",
    "\t# discriminator element\n",
    "\tinput_gen = Input(shape=image_shape)\n",
    "\tgen1_out = g_model_1(input_gen)\n",
    "\toutput_d = d_model(gen1_out)\n",
    "\t# identity element\n",
    "\tinput_id = Input(shape=image_shape)\n",
    "\toutput_id = g_model_1(input_id)\n",
    "\t# forward cycle\n",
    "\toutput_f = g_model_2(gen1_out)\n",
    "\t# backward cycle\n",
    "\tgen2_out = g_model_2(input_id)\n",
    "\toutput_b = g_model_1(gen2_out)\n",
    "\t# define model graph\n",
    "\tmodel = Model([input_gen, input_id], [output_d, output_id, output_f, output_b])\n",
    "\t# define optimization algorithm configuration\n",
    "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
    "\t# compile model with weighting of least squares loss and L1 loss\n",
    "\tmodel.compile(loss=['mse', 'mae', 'mae', 'mae'], loss_weights=[1, 5, 10, 10], optimizer=opt)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "# select a batch of random samples, returns images and target\n",
    "def generate_real_samples(dataset, n_samples, patch_shape, patch_shape2):\n",
    "    # choose random instances\n",
    "    #print(dataset.shape[0])\n",
    "    #print(n_samples)\n",
    "    ix = randint(0, dataset.shape[0]-1)\n",
    "    #print(ix)\n",
    "    # retrieve selected images\n",
    "    X = dataset[ix:ix+n_samples]\n",
    "    #print(X.shape)\n",
    "    # generate 'real' class labels (1)\n",
    "    y = ones((n_samples, patch_shape, patch_shape2, 1))\n",
    "    #print(y.shape)\n",
    "    return X, y\n",
    "# generate a batch of images, returns images and targets\n",
    "def generate_fake_samples(g_model, dataset, patch_shape, patch_shape2):\n",
    "\t# generate fake instance\n",
    "\tX = g_model.predict(dataset)\n",
    "\t# create 'fake' class labels (0)\n",
    "\ty = zeros((len(X), patch_shape, patch_shape2, 1))\n",
    "    #print(y.shape)\n",
    "\treturn X, y\n",
    "\n",
    "# select a batch of real samples\n",
    "#X_realA, y_realA = generate_real_samples(trainA, n_batch, n_patch)\n",
    "#X_realB, y_realB = generate_real_samples(trainB, n_batch, n_patch)\n",
    "# generate a batch of fake samples\n",
    "#X_fakeA, y_fakeA = generate_fake_samples(g_model_BtoA, X_realB, n_patch)\n",
    "#X_fakeB, y_fakeB = generate_fake_samples(g_model_AtoB, X_realA, n_patch)\n",
    "# update image pool for fake images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import random\n",
    "def update_image_pool(pool, images, max_size=50):\n",
    "\tselected = list()\n",
    "\tfor image in images:\n",
    "\t\tif len(pool) < max_size:\n",
    "\t\t\t# stock the pool\n",
    "\t\t\tpool.append(image)\n",
    "\t\t\tselected.append(image)\n",
    "\t\telif random() < 0.5:\n",
    "\t\t\t# use image, but don't add it to the pool\n",
    "\t\t\tselected.append(image)\n",
    "\t\telse:\n",
    "\t\t\t# replace an existing image and use replaced image\n",
    "\t\t\t#print(len(pool))\n",
    "\t\t\tix = randint(0, len(pool)-1)\n",
    "\t\t\tselected.append(pool[ix])\n",
    "\t\t\tpool[ix] = image\n",
    "\treturn np.asarray(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(trainA,trainB,model_BtoA,model_AtoB,n_patch,n_patch2,epoch):\n",
    "        c = 3\n",
    "        #print(trainA.shape)\n",
    "        imgs_A, _ = generate_real_samples(trainA, 1, n_patch, n_patch2)\n",
    "        imgs_B, _ = generate_real_samples(trainB, 1, n_patch, n_patch2)\n",
    "        #print(imgs_A.shape)\n",
    "        # Translate images to the other domain\n",
    "        fake_B, _ = generate_fake_samples(model_AtoB, imgs_A, n_patch, n_patch2)\n",
    "        fake_A, _ = generate_fake_samples(model_BtoA, imgs_B, n_patch, n_patch2)\n",
    "        # Translate back to original domain\n",
    "        reconstr_A, _ = generate_fake_samples(model_BtoA, fake_B, n_patch, n_patch2)\n",
    "        reconstr_B, _ = generate_fake_samples(model_AtoB, fake_A, n_patch, n_patch2)\n",
    "\n",
    "        gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, imgs_B, fake_A, reconstr_B])\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        titles = ['Original', 'Translated', 'Reconstructed']\n",
    "        fig1, axs1 = plt.subplots(c)\n",
    "\n",
    "        cnt = 0\n",
    "        for j in range(c):\n",
    "            axs1[j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
    "            axs1[j].set_title(titles[j])\n",
    "            axs1[j].axis('off')\n",
    "            cnt += 1\n",
    "        fig1.savefig(\"images_cycle/AtoB/%d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "        fig2, axs2 = plt.subplots(c)\n",
    "        cnt = 3\n",
    "        for i in range(c):\n",
    "            axs2[i].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
    "            axs2[i].set_title(titles[i])\n",
    "            axs2[i].axis('off')\n",
    "            cnt += 1\n",
    "        fig2.savefig(\"images_cycle/BtoA/%d.png\" % epoch)\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train cyclegan models\n",
    "def train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset):\n",
    "    # define properties of the training run\n",
    "    n_epochs, n_batch, = 100, 1\n",
    "    # determine the output square shape of the discriminator\n",
    "    #print(d_model_A.output_shape)\n",
    "    n_patch = d_model_A.output_shape[1]\n",
    "    n_patch2 = d_model_A.output_shape[2]\n",
    "    # unpack dataset\n",
    "    trainA, trainB = dataset\n",
    "    #print(trainA.shape)\n",
    "    #print(trainB.shape)\n",
    "    # prepare image pool for fakes\n",
    "    poolA, poolB = list(), list()\n",
    "    # calculate the number of batches per training epoch\n",
    "    bat_per_epo = int(len(trainA) / n_batch)\n",
    "    # calculate the number of training iterations\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_steps):\n",
    "        # select a batch of real samples\n",
    "        X_realA, y_realA = generate_real_samples(trainA, n_batch, n_patch, n_patch2)\n",
    "        X_realB, y_realB = generate_real_samples(trainB, n_batch, n_patch, n_patch2)\n",
    "        # generate a batch of fake samples\n",
    "        X_fakeA, y_fakeA = generate_fake_samples(g_model_BtoA, X_realB, n_patch, n_patch2)\n",
    "        X_fakeB, y_fakeB = generate_fake_samples(g_model_AtoB, X_realA, n_patch, n_patch2)\n",
    "        # update fakes from pool\n",
    "        X_fakeA = update_image_pool(poolA, X_fakeA)\n",
    "        X_fakeB = update_image_pool(poolB, X_fakeB)\n",
    "        # update generator B->A via adversarial and cycle loss\n",
    "        g_loss2, _, _, _, _  = c_model_BtoA.train_on_batch([X_realB, X_realA], [y_realA, X_realA, X_realB, X_realA])\n",
    "        # update discriminator for A -> [real/fake]\n",
    "        dA_loss1 = d_model_A.train_on_batch(X_realA, y_realA)\n",
    "        dA_loss2 = d_model_A.train_on_batch(X_fakeA, y_fakeA)\n",
    "        # update generator A->B via adversarial and cycle loss\n",
    "        g_loss1, _, _, _, _ = c_model_AtoB.train_on_batch([X_realA, X_realB], [y_realB, X_realB, X_realA, X_realB])\n",
    "        # update discriminator for B -> [real/fake]\n",
    "        dB_loss1 = d_model_B.train_on_batch(X_realB, y_realB)\n",
    "        dB_loss2 = d_model_B.train_on_batch(X_fakeB, y_fakeB)\n",
    "        # summarize performance\n",
    "        print('>%d, dA[loss1:%.3f,loss2:%.3f] dB[loss1:%.3f,loss2:%.3f] g[loss1:%.3f,loss2:%.3f]' % (i+1, dA_loss1,dA_loss2, dB_loss1,dB_loss2, g_loss1,g_loss2))\n",
    "        # If at save interval => save generated image samples\n",
    "        if i % 100 == 0:\n",
    "          sample_images(trainA,trainB,g_model_BtoA,g_model_AtoB,n_patch,n_patch2,(i/100))\n",
    "          d_model_A.save('saved_model/p2hDiscA_2_%d.h5' % (i/100))\n",
    "          d_model_B.save('saved_model/p2hDiscB_2_%d.h5' % (i/100))\n",
    "          g_model_AtoB.save('saved_model/p2hGenAB_2_%d.h5' % (i/100))\n",
    "          g_model_BtoA.save('saved_model/p2hGenBA_2_%d.h5' % (i/100))\n",
    "          print('model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def load_imgs():\n",
    "    # load Printed dataset\n",
    "    printed_dir = 'datasets2/words/trainA/'\n",
    "    printed_imgs = list()\n",
    "    for f in os.listdir(printed_dir):\n",
    "      #load the image\n",
    "      #img = image.imread(printed_dir + '/' + f,'r').convert('L')\n",
    "      img = cv2.imread(printed_dir + '/' + f, cv2.IMREAD_GRAYSCALE)\n",
    "      #Resize to same as hw_imgs\n",
    "      dim = (256,64)\n",
    "      img = cv2.resize(img, dim, interpolation = cv2.INTER_LINEAR)\n",
    "      printed_imgs.append(img)\n",
    "    # load HW dataset\n",
    "    hw_dir = 'datasets2/words/trainB/'\n",
    "    hw_imgs = list()\n",
    "    for f in os.listdir(hw_dir):\n",
    "      #load the image\n",
    "      img = cv2.imread(hw_dir + '/' + f, cv2.IMREAD_GRAYSCALE)\n",
    "      #Resize to same as hw_imgs\n",
    "      dim = (256,64)\n",
    "      img = cv2.resize(img, dim, interpolation = cv2.INTER_LINEAR)\n",
    "      hw_imgs.append(img)\n",
    "    # load printed test dataset\n",
    "    printed2_dir = 'datasets/sentences/testA/'\n",
    "    printed2_imgs = list()\n",
    "    for f in os.listdir(printed2_dir):\n",
    "      #load the image\n",
    "      img = image.imread(printed2_dir + '/' + f,'r')\n",
    "      printed2_imgs.append(img)\n",
    "    # load HW test dataset\n",
    "    hw_dir2 = 'datasets/sentences/testB/'\n",
    "    hw_imgs2 = list()\n",
    "    for f in os.listdir(hw_dir2):\n",
    "      #load the image\n",
    "      img2 = image.imread(hw_dir2 + '/' + f,'r')\n",
    "      hw_imgs2.append(img2)\n",
    "    printed_imgs = np.asarray(printed_imgs).astype('float32') / 255\n",
    "    hw_imgs = np.asarray(hw_imgs).astype('float32') / 255\n",
    "    hw_imgs2 = np.asarray(hw_imgs2).astype('float32') / 255\n",
    "    printed2_imgs = np.asarray(printed2_imgs).astype('float32') / 255\n",
    "    printed_imgs = printed_imgs.reshape(printed_imgs.shape[0],\n",
    "                                      printed_imgs.shape[1],\n",
    "                                      printed_imgs.shape[2],\n",
    "                                      1)\n",
    "    hw_imgs = hw_imgs.reshape(hw_imgs.shape[0],\n",
    "                                      hw_imgs.shape[1],\n",
    "                                      hw_imgs.shape[2],\n",
    "                                      1)\n",
    "    printed2_imgs = printed2_imgs.reshape(printed2_imgs.shape[0],\n",
    "                                      printed2_imgs.shape[1],\n",
    "                                      printed2_imgs.shape[2],\n",
    "                                      1)\n",
    "    hw_imgs2 = hw_imgs2.reshape(hw_imgs2.shape[0],\n",
    "                                      hw_imgs2.shape[1],\n",
    "                                      hw_imgs2.shape[2],\n",
    "                                      1)\n",
    "\n",
    "    return printed_imgs, hw_imgs, printed2_imgs, hw_imgs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(186, 64, 256, 1)\n",
      "(500, 64, 256, 1)\n",
      "(60, 48, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "# load a dataset as a list of two numpy arrays\n",
    "trainA, trainB,testA, testB = load_imgs()\n",
    "print(trainA.shape)\n",
    "print(trainB.shape)\n",
    "print(testB.shape)\n",
    "dataset = (trainA, trainB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(186, 64, 256, 1)\n",
      "(500, 64, 256, 1)\n",
      "(60, 48, 512, 1)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_41 (InputLayer)           (None, 64, 256, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 64, 256, 32)  1600        input_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_281 (Ins (None, 64, 256, 32)  64          conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 64, 256, 32)  0           instance_normalization_281[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_282 (Conv2D)             (None, 32, 128, 64)  18496       activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_282 (Ins (None, 32, 128, 64)  128         conv2d_282[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 32, 128, 64)  0           instance_normalization_282[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)             (None, 16, 64, 128)  73856       activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_283 (Ins (None, 16, 64, 128)  256         conv2d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 16, 64, 128)  0           instance_normalization_283[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)             (None, 16, 64, 128)  147584      activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_284 (Ins (None, 16, 64, 128)  256         conv2d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 16, 64, 128)  0           instance_normalization_284[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_285 (Conv2D)             (None, 16, 64, 128)  147584      activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_285 (Ins (None, 16, 64, 128)  256         conv2d_285[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_91 (Concatenate)    (None, 16, 64, 256)  0           instance_normalization_285[0][0] \n",
      "                                                                 activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_286 (Conv2D)             (None, 16, 64, 128)  295040      concatenate_91[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_286 (Ins (None, 16, 64, 128)  256         conv2d_286[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 16, 64, 128)  0           instance_normalization_286[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_287 (Conv2D)             (None, 16, 64, 128)  147584      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_287 (Ins (None, 16, 64, 128)  256         conv2d_287[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_92 (Concatenate)    (None, 16, 64, 384)  0           instance_normalization_287[0][0] \n",
      "                                                                 concatenate_91[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_288 (Conv2D)             (None, 16, 64, 128)  442496      concatenate_92[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_288 (Ins (None, 16, 64, 128)  256         conv2d_288[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 16, 64, 128)  0           instance_normalization_288[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_289 (Conv2D)             (None, 16, 64, 128)  147584      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_289 (Ins (None, 16, 64, 128)  256         conv2d_289[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_93 (Concatenate)    (None, 16, 64, 512)  0           instance_normalization_289[0][0] \n",
      "                                                                 concatenate_92[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_290 (Conv2D)             (None, 16, 64, 128)  589952      concatenate_93[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_290 (Ins (None, 16, 64, 128)  256         conv2d_290[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 16, 64, 128)  0           instance_normalization_290[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_291 (Conv2D)             (None, 16, 64, 128)  147584      activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_291 (Ins (None, 16, 64, 128)  256         conv2d_291[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_94 (Concatenate)    (None, 16, 64, 640)  0           instance_normalization_291[0][0] \n",
      "                                                                 concatenate_93[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_292 (Conv2D)             (None, 16, 64, 128)  737408      concatenate_94[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_292 (Ins (None, 16, 64, 128)  256         conv2d_292[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 16, 64, 128)  0           instance_normalization_292[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_293 (Conv2D)             (None, 16, 64, 128)  147584      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_293 (Ins (None, 16, 64, 128)  256         conv2d_293[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_95 (Concatenate)    (None, 16, 64, 768)  0           instance_normalization_293[0][0] \n",
      "                                                                 concatenate_94[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_294 (Conv2D)             (None, 16, 64, 128)  884864      concatenate_95[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_294 (Ins (None, 16, 64, 128)  256         conv2d_294[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 16, 64, 128)  0           instance_normalization_294[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_295 (Conv2D)             (None, 16, 64, 128)  147584      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_295 (Ins (None, 16, 64, 128)  256         conv2d_295[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_96 (Concatenate)    (None, 16, 64, 896)  0           instance_normalization_295[0][0] \n",
      "                                                                 concatenate_95[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_296 (Conv2D)             (None, 16, 64, 128)  1032320     concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_296 (Ins (None, 16, 64, 128)  256         conv2d_296[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 16, 64, 128)  0           instance_normalization_296[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_297 (Conv2D)             (None, 16, 64, 128)  147584      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_297 (Ins (None, 16, 64, 128)  256         conv2d_297[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_97 (Concatenate)    (None, 16, 64, 1024) 0           instance_normalization_297[0][0] \n",
      "                                                                 concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_298 (Conv2D)             (None, 16, 64, 128)  1179776     concatenate_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_298 (Ins (None, 16, 64, 128)  256         conv2d_298[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 16, 64, 128)  0           instance_normalization_298[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_299 (Conv2D)             (None, 16, 64, 128)  147584      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_299 (Ins (None, 16, 64, 128)  256         conv2d_299[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_98 (Concatenate)    (None, 16, 64, 1152) 0           instance_normalization_299[0][0] \n",
      "                                                                 concatenate_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_300 (Conv2D)             (None, 16, 64, 128)  1327232     concatenate_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_300 (Ins (None, 16, 64, 128)  256         conv2d_300[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 16, 64, 128)  0           instance_normalization_300[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_301 (Conv2D)             (None, 16, 64, 128)  147584      activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_301 (Ins (None, 16, 64, 128)  256         conv2d_301[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_99 (Concatenate)    (None, 16, 64, 1280) 0           instance_normalization_301[0][0] \n",
      "                                                                 concatenate_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_21 (Conv2DTran (None, 32, 128, 64)  737344      concatenate_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_302 (Ins (None, 32, 128, 64)  128         conv2d_transpose_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 32, 128, 64)  0           instance_normalization_302[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_22 (Conv2DTran (None, 64, 256, 32)  18464       activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_303 (Ins (None, 64, 256, 32)  64          conv2d_transpose_22[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 64, 256, 32)  0           instance_normalization_303[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_302 (Conv2D)             (None, 64, 256, 1)   1569        activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_304 (Ins (None, 64, 256, 1)   2           conv2d_302[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 64, 256, 1)   0           instance_normalization_304[0][0] \n",
      "==================================================================================================\n",
      "Total params: 8,821,507\n",
      "Trainable params: 8,821,507\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_42 (InputLayer)           (None, 64, 256, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_303 (Conv2D)             (None, 64, 256, 32)  1600        input_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_305 (Ins (None, 64, 256, 32)  64          conv2d_303[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 64, 256, 32)  0           instance_normalization_305[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_304 (Conv2D)             (None, 32, 128, 64)  18496       activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_306 (Ins (None, 32, 128, 64)  128         conv2d_304[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 32, 128, 64)  0           instance_normalization_306[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_305 (Conv2D)             (None, 16, 64, 128)  73856       activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_307 (Ins (None, 16, 64, 128)  256         conv2d_305[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 16, 64, 128)  0           instance_normalization_307[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_306 (Conv2D)             (None, 16, 64, 128)  147584      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_308 (Ins (None, 16, 64, 128)  256         conv2d_306[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 16, 64, 128)  0           instance_normalization_308[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_307 (Conv2D)             (None, 16, 64, 128)  147584      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_309 (Ins (None, 16, 64, 128)  256         conv2d_307[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_100 (Concatenate)   (None, 16, 64, 256)  0           instance_normalization_309[0][0] \n",
      "                                                                 activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_308 (Conv2D)             (None, 16, 64, 128)  295040      concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_310 (Ins (None, 16, 64, 128)  256         conv2d_308[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 16, 64, 128)  0           instance_normalization_310[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_309 (Conv2D)             (None, 16, 64, 128)  147584      activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_311 (Ins (None, 16, 64, 128)  256         conv2d_309[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_101 (Concatenate)   (None, 16, 64, 384)  0           instance_normalization_311[0][0] \n",
      "                                                                 concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_310 (Conv2D)             (None, 16, 64, 128)  442496      concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_312 (Ins (None, 16, 64, 128)  256         conv2d_310[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 16, 64, 128)  0           instance_normalization_312[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_311 (Conv2D)             (None, 16, 64, 128)  147584      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_313 (Ins (None, 16, 64, 128)  256         conv2d_311[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_102 (Concatenate)   (None, 16, 64, 512)  0           instance_normalization_313[0][0] \n",
      "                                                                 concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_312 (Conv2D)             (None, 16, 64, 128)  589952      concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_314 (Ins (None, 16, 64, 128)  256         conv2d_312[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 16, 64, 128)  0           instance_normalization_314[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_313 (Conv2D)             (None, 16, 64, 128)  147584      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_315 (Ins (None, 16, 64, 128)  256         conv2d_313[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_103 (Concatenate)   (None, 16, 64, 640)  0           instance_normalization_315[0][0] \n",
      "                                                                 concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_314 (Conv2D)             (None, 16, 64, 128)  737408      concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_316 (Ins (None, 16, 64, 128)  256         conv2d_314[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 16, 64, 128)  0           instance_normalization_316[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_315 (Conv2D)             (None, 16, 64, 128)  147584      activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_317 (Ins (None, 16, 64, 128)  256         conv2d_315[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_104 (Concatenate)   (None, 16, 64, 768)  0           instance_normalization_317[0][0] \n",
      "                                                                 concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_316 (Conv2D)             (None, 16, 64, 128)  884864      concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_318 (Ins (None, 16, 64, 128)  256         conv2d_316[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 16, 64, 128)  0           instance_normalization_318[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_317 (Conv2D)             (None, 16, 64, 128)  147584      activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_319 (Ins (None, 16, 64, 128)  256         conv2d_317[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_105 (Concatenate)   (None, 16, 64, 896)  0           instance_normalization_319[0][0] \n",
      "                                                                 concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_318 (Conv2D)             (None, 16, 64, 128)  1032320     concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_320 (Ins (None, 16, 64, 128)  256         conv2d_318[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 16, 64, 128)  0           instance_normalization_320[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_319 (Conv2D)             (None, 16, 64, 128)  147584      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_321 (Ins (None, 16, 64, 128)  256         conv2d_319[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_106 (Concatenate)   (None, 16, 64, 1024) 0           instance_normalization_321[0][0] \n",
      "                                                                 concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_320 (Conv2D)             (None, 16, 64, 128)  1179776     concatenate_106[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_322 (Ins (None, 16, 64, 128)  256         conv2d_320[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 16, 64, 128)  0           instance_normalization_322[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_321 (Conv2D)             (None, 16, 64, 128)  147584      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_323 (Ins (None, 16, 64, 128)  256         conv2d_321[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_107 (Concatenate)   (None, 16, 64, 1152) 0           instance_normalization_323[0][0] \n",
      "                                                                 concatenate_106[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_322 (Conv2D)             (None, 16, 64, 128)  1327232     concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_324 (Ins (None, 16, 64, 128)  256         conv2d_322[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 16, 64, 128)  0           instance_normalization_324[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_323 (Conv2D)             (None, 16, 64, 128)  147584      activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_325 (Ins (None, 16, 64, 128)  256         conv2d_323[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_108 (Concatenate)   (None, 16, 64, 1280) 0           instance_normalization_325[0][0] \n",
      "                                                                 concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_23 (Conv2DTran (None, 32, 128, 64)  737344      concatenate_108[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_326 (Ins (None, 32, 128, 64)  128         conv2d_transpose_23[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 32, 128, 64)  0           instance_normalization_326[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_24 (Conv2DTran (None, 64, 256, 32)  18464       activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_327 (Ins (None, 64, 256, 32)  64          conv2d_transpose_24[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 64, 256, 32)  0           instance_normalization_327[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_324 (Conv2D)             (None, 64, 256, 1)   1569        activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_328 (Ins (None, 64, 256, 1)   2           conv2d_324[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 64, 256, 1)   0           instance_normalization_328[0][0] \n",
      "==================================================================================================\n",
      "Total params: 8,821,507\n",
      "Trainable params: 8,821,507\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_43 (InputLayer)        (None, 64, 256, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_325 (Conv2D)          (None, 32, 128, 32)       544       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_51 (LeakyReLU)   (None, 32, 128, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_326 (Conv2D)          (None, 16, 64, 64)        32832     \n",
      "_________________________________________________________________\n",
      "instance_normalization_329 ( (None, 16, 64, 64)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_52 (LeakyReLU)   (None, 16, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_327 (Conv2D)          (None, 8, 32, 128)        131200    \n",
      "_________________________________________________________________\n",
      "instance_normalization_330 ( (None, 8, 32, 128)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_53 (LeakyReLU)   (None, 8, 32, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_328 (Conv2D)          (None, 4, 16, 256)        524544    \n",
      "_________________________________________________________________\n",
      "instance_normalization_331 ( (None, 4, 16, 256)        512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_54 (LeakyReLU)   (None, 4, 16, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_329 (Conv2D)          (None, 4, 16, 256)        1048832   \n",
      "_________________________________________________________________\n",
      "instance_normalization_332 ( (None, 4, 16, 256)        512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_55 (LeakyReLU)   (None, 4, 16, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_330 (Conv2D)          (None, 4, 16, 1)          4097      \n",
      "=================================================================\n",
      "Total params: 1,743,457\n",
      "Trainable params: 1,743,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_44 (InputLayer)        (None, 64, 256, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_331 (Conv2D)          (None, 32, 128, 32)       544       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_56 (LeakyReLU)   (None, 32, 128, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_332 (Conv2D)          (None, 16, 64, 64)        32832     \n",
      "_________________________________________________________________\n",
      "instance_normalization_333 ( (None, 16, 64, 64)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_57 (LeakyReLU)   (None, 16, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_333 (Conv2D)          (None, 8, 32, 128)        131200    \n",
      "_________________________________________________________________\n",
      "instance_normalization_334 ( (None, 8, 32, 128)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_58 (LeakyReLU)   (None, 8, 32, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_334 (Conv2D)          (None, 4, 16, 256)        524544    \n",
      "_________________________________________________________________\n",
      "instance_normalization_335 ( (None, 4, 16, 256)        512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_59 (LeakyReLU)   (None, 4, 16, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_335 (Conv2D)          (None, 4, 16, 256)        1048832   \n",
      "_________________________________________________________________\n",
      "instance_normalization_336 ( (None, 4, 16, 256)        512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_60 (LeakyReLU)   (None, 4, 16, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_336 (Conv2D)          (None, 4, 16, 1)          4097      \n",
      "=================================================================\n",
      "Total params: 1,743,457\n",
      "Trainable params: 1,743,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ellysah\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "C:\\Users\\Ellysah\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "C:\\Users\\Ellysah\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "C:\\Users\\Ellysah\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1, dA[loss1:0.811,loss2:0.297] dB[loss1:1.912,loss2:0.299] g[loss1:27.521,loss2:26.221]\n",
      "model saved\n",
      ">2, dA[loss1:0.995,loss2:0.438] dB[loss1:0.982,loss2:0.289] g[loss1:24.476,loss2:24.784]\n",
      ">3, dA[loss1:1.253,loss2:0.349] dB[loss1:0.806,loss2:0.558] g[loss1:24.635,loss2:24.235]\n",
      ">4, dA[loss1:0.200,loss2:0.230] dB[loss1:0.675,loss2:1.085] g[loss1:23.764,loss2:23.650]\n",
      ">5, dA[loss1:1.110,loss2:0.274] dB[loss1:0.534,loss2:1.422] g[loss1:23.610,loss2:23.319]\n",
      ">6, dA[loss1:1.240,loss2:0.405] dB[loss1:0.676,loss2:1.748] g[loss1:21.648,loss2:23.348]\n",
      ">7, dA[loss1:0.446,loss2:0.529] dB[loss1:0.401,loss2:0.870] g[loss1:20.721,loss2:21.584]\n",
      ">8, dA[loss1:0.206,loss2:0.356] dB[loss1:0.196,loss2:0.432] g[loss1:20.983,loss2:21.182]\n",
      ">9, dA[loss1:0.125,loss2:0.194] dB[loss1:0.260,loss2:0.211] g[loss1:19.679,loss2:20.541]\n",
      ">10, dA[loss1:0.103,loss2:0.315] dB[loss1:0.417,loss2:0.152] g[loss1:20.962,loss2:20.596]\n",
      ">11, dA[loss1:0.157,loss2:0.236] dB[loss1:0.297,loss2:0.216] g[loss1:20.289,loss2:20.495]\n",
      ">12, dA[loss1:0.187,loss2:0.212] dB[loss1:0.204,loss2:0.323] g[loss1:19.861,loss2:20.401]\n",
      ">13, dA[loss1:0.167,loss2:0.546] dB[loss1:0.236,loss2:0.338] g[loss1:20.478,loss2:20.896]\n",
      ">14, dA[loss1:0.229,loss2:0.289] dB[loss1:0.206,loss2:0.452] g[loss1:19.519,loss2:20.399]\n",
      ">15, dA[loss1:0.275,loss2:0.217] dB[loss1:0.265,loss2:0.658] g[loss1:21.049,loss2:20.039]\n",
      ">16, dA[loss1:0.132,loss2:0.284] dB[loss1:0.281,loss2:0.409] g[loss1:19.233,loss2:19.872]\n",
      ">17, dA[loss1:0.106,loss2:0.490] dB[loss1:0.133,loss2:0.279] g[loss1:18.575,loss2:20.050]\n",
      ">18, dA[loss1:0.294,loss2:0.285] dB[loss1:0.335,loss2:0.574] g[loss1:19.624,loss2:19.218]\n",
      ">19, dA[loss1:0.111,loss2:0.459] dB[loss1:0.146,loss2:0.726] g[loss1:18.960,loss2:20.148]\n",
      ">20, dA[loss1:0.112,loss2:0.179] dB[loss1:0.164,loss2:0.224] g[loss1:19.872,loss2:20.348]\n",
      ">21, dA[loss1:0.064,loss2:0.232] dB[loss1:0.119,loss2:0.145] g[loss1:19.247,loss2:19.358]\n",
      ">22, dA[loss1:0.117,loss2:0.170] dB[loss1:0.106,loss2:0.131] g[loss1:19.929,loss2:20.330]\n",
      ">23, dA[loss1:0.076,loss2:0.169] dB[loss1:0.142,loss2:0.135] g[loss1:19.237,loss2:19.383]\n",
      ">24, dA[loss1:0.050,loss2:0.166] dB[loss1:0.129,loss2:0.296] g[loss1:19.735,loss2:19.569]\n",
      ">25, dA[loss1:0.098,loss2:0.187] dB[loss1:0.124,loss2:0.118] g[loss1:18.420,loss2:19.633]\n",
      ">26, dA[loss1:0.131,loss2:0.180] dB[loss1:0.113,loss2:0.173] g[loss1:18.982,loss2:19.624]\n",
      ">27, dA[loss1:0.119,loss2:0.174] dB[loss1:0.074,loss2:0.211] g[loss1:18.479,loss2:19.601]\n",
      ">28, dA[loss1:0.104,loss2:0.135] dB[loss1:0.127,loss2:0.199] g[loss1:18.853,loss2:19.284]\n",
      ">29, dA[loss1:0.062,loss2:0.146] dB[loss1:0.104,loss2:0.087] g[loss1:19.125,loss2:20.231]\n",
      ">30, dA[loss1:0.042,loss2:0.087] dB[loss1:0.156,loss2:0.103] g[loss1:20.232,loss2:20.211]\n",
      ">31, dA[loss1:0.080,loss2:0.136] dB[loss1:0.101,loss2:0.116] g[loss1:19.081,loss2:19.363]\n",
      ">32, dA[loss1:0.061,loss2:0.129] dB[loss1:0.109,loss2:0.178] g[loss1:19.609,loss2:20.249]\n",
      ">33, dA[loss1:0.051,loss2:0.140] dB[loss1:0.141,loss2:0.319] g[loss1:18.889,loss2:18.971]\n",
      ">34, dA[loss1:0.054,loss2:0.462] dB[loss1:0.103,loss2:0.462] g[loss1:19.540,loss2:20.664]\n",
      ">35, dA[loss1:0.082,loss2:0.142] dB[loss1:0.123,loss2:0.718] g[loss1:20.172,loss2:20.089]\n",
      ">36, dA[loss1:0.135,loss2:0.315] dB[loss1:0.185,loss2:0.700] g[loss1:20.476,loss2:20.697]\n",
      ">37, dA[loss1:0.073,loss2:0.102] dB[loss1:0.255,loss2:0.128] g[loss1:18.817,loss2:18.618]\n",
      ">38, dA[loss1:0.053,loss2:0.126] dB[loss1:0.166,loss2:0.175] g[loss1:17.746,loss2:18.974]\n",
      ">39, dA[loss1:0.037,loss2:0.075] dB[loss1:0.078,loss2:0.075] g[loss1:19.770,loss2:19.453]\n",
      ">40, dA[loss1:0.057,loss2:0.048] dB[loss1:0.080,loss2:0.245] g[loss1:19.252,loss2:19.779]\n",
      ">41, dA[loss1:0.047,loss2:0.084] dB[loss1:0.071,loss2:0.111] g[loss1:19.018,loss2:19.636]\n",
      ">42, dA[loss1:0.082,loss2:0.121] dB[loss1:0.116,loss2:0.194] g[loss1:17.273,loss2:18.454]\n",
      ">43, dA[loss1:0.058,loss2:0.081] dB[loss1:0.164,loss2:0.162] g[loss1:17.752,loss2:18.494]\n",
      ">44, dA[loss1:0.059,loss2:0.035] dB[loss1:0.097,loss2:0.222] g[loss1:19.098,loss2:19.378]\n",
      ">45, dA[loss1:0.043,loss2:0.044] dB[loss1:0.113,loss2:0.964] g[loss1:20.135,loss2:19.523]\n",
      ">46, dA[loss1:0.027,loss2:0.068] dB[loss1:0.109,loss2:0.730] g[loss1:19.427,loss2:18.985]\n",
      ">47, dA[loss1:0.021,loss2:0.101] dB[loss1:0.128,loss2:0.718] g[loss1:19.873,loss2:19.837]\n",
      ">48, dA[loss1:0.037,loss2:0.092] dB[loss1:0.109,loss2:0.258] g[loss1:19.462,loss2:19.555]\n",
      ">49, dA[loss1:0.071,loss2:0.052] dB[loss1:0.062,loss2:0.119] g[loss1:18.870,loss2:19.342]\n",
      ">50, dA[loss1:0.076,loss2:0.064] dB[loss1:0.058,loss2:0.068] g[loss1:18.870,loss2:19.706]\n",
      ">51, dA[loss1:0.071,loss2:0.058] dB[loss1:0.086,loss2:0.222] g[loss1:18.960,loss2:19.329]\n",
      ">52, dA[loss1:0.035,loss2:0.268] dB[loss1:0.080,loss2:0.112] g[loss1:18.692,loss2:19.065]\n",
      ">53, dA[loss1:0.053,loss2:0.087] dB[loss1:0.104,loss2:0.207] g[loss1:17.453,loss2:18.323]\n",
      ">54, dA[loss1:0.064,loss2:0.134] dB[loss1:0.059,loss2:0.050] g[loss1:18.342,loss2:19.025]\n",
      ">55, dA[loss1:0.034,loss2:0.063] dB[loss1:0.080,loss2:0.328] g[loss1:18.063,loss2:18.648]\n",
      ">56, dA[loss1:0.054,loss2:0.423] dB[loss1:0.076,loss2:0.062] g[loss1:17.632,loss2:19.054]\n",
      ">57, dA[loss1:0.056,loss2:0.121] dB[loss1:0.088,loss2:0.153] g[loss1:19.133,loss2:19.376]\n",
      ">58, dA[loss1:0.029,loss2:0.066] dB[loss1:0.083,loss2:0.149] g[loss1:19.155,loss2:19.184]\n",
      ">59, dA[loss1:0.039,loss2:0.071] dB[loss1:0.094,loss2:0.082] g[loss1:18.820,loss2:19.131]\n",
      ">60, dA[loss1:0.021,loss2:0.032] dB[loss1:0.065,loss2:0.148] g[loss1:19.006,loss2:19.427]\n",
      ">61, dA[loss1:0.031,loss2:0.033] dB[loss1:0.045,loss2:0.225] g[loss1:18.650,loss2:19.180]\n",
      ">62, dA[loss1:0.031,loss2:0.087] dB[loss1:0.059,loss2:0.093] g[loss1:19.477,loss2:19.237]\n",
      ">63, dA[loss1:0.023,loss2:0.045] dB[loss1:0.064,loss2:0.108] g[loss1:18.566,loss2:19.253]\n",
      ">64, dA[loss1:0.037,loss2:0.050] dB[loss1:0.050,loss2:0.160] g[loss1:18.854,loss2:19.245]\n",
      ">65, dA[loss1:0.011,loss2:0.035] dB[loss1:0.107,loss2:0.155] g[loss1:18.910,loss2:19.158]\n",
      ">66, dA[loss1:0.075,loss2:0.062] dB[loss1:0.067,loss2:0.048] g[loss1:18.453,loss2:19.202]\n",
      ">67, dA[loss1:0.054,loss2:0.111] dB[loss1:0.074,loss2:0.042] g[loss1:18.068,loss2:18.494]\n",
      ">68, dA[loss1:0.026,loss2:0.085] dB[loss1:0.070,loss2:0.069] g[loss1:17.487,loss2:18.735]\n",
      ">69, dA[loss1:0.043,loss2:0.056] dB[loss1:0.059,loss2:0.023] g[loss1:19.490,loss2:20.144]\n",
      ">70, dA[loss1:0.027,loss2:0.060] dB[loss1:0.061,loss2:0.169] g[loss1:19.090,loss2:19.412]\n",
      ">71, dA[loss1:0.025,loss2:0.081] dB[loss1:0.057,loss2:0.088] g[loss1:19.145,loss2:19.619]\n",
      ">72, dA[loss1:0.019,loss2:0.032] dB[loss1:0.071,loss2:0.063] g[loss1:18.224,loss2:18.815]\n",
      ">73, dA[loss1:0.024,loss2:0.079] dB[loss1:0.055,loss2:0.125] g[loss1:17.762,loss2:18.567]\n",
      ">74, dA[loss1:0.038,loss2:0.056] dB[loss1:0.059,loss2:0.052] g[loss1:19.887,loss2:19.436]\n",
      ">75, dA[loss1:0.047,loss2:0.064] dB[loss1:0.094,loss2:0.077] g[loss1:18.212,loss2:18.714]\n",
      ">76, dA[loss1:0.017,loss2:0.103] dB[loss1:0.091,loss2:0.037] g[loss1:19.631,loss2:19.537]\n",
      ">77, dA[loss1:0.023,loss2:0.069] dB[loss1:0.037,loss2:0.036] g[loss1:19.580,loss2:19.632]\n",
      ">78, dA[loss1:0.039,loss2:0.037] dB[loss1:0.096,loss2:0.082] g[loss1:19.419,loss2:19.645]\n",
      ">79, dA[loss1:0.022,loss2:0.051] dB[loss1:0.079,loss2:0.043] g[loss1:18.664,loss2:19.010]\n",
      ">80, dA[loss1:0.026,loss2:0.077] dB[loss1:0.030,loss2:0.116] g[loss1:18.895,loss2:19.096]\n",
      ">81, dA[loss1:0.026,loss2:0.094] dB[loss1:0.123,loss2:0.273] g[loss1:19.168,loss2:19.338]\n",
      ">82, dA[loss1:0.020,loss2:0.073] dB[loss1:0.086,loss2:0.048] g[loss1:18.900,loss2:18.748]\n",
      ">83, dA[loss1:0.047,loss2:0.032] dB[loss1:0.087,loss2:0.558] g[loss1:18.124,loss2:17.923]\n",
      ">84, dA[loss1:0.058,loss2:0.033] dB[loss1:0.076,loss2:0.108] g[loss1:18.621,loss2:18.708]\n",
      ">85, dA[loss1:0.014,loss2:0.026] dB[loss1:0.054,loss2:0.305] g[loss1:17.998,loss2:18.165]\n",
      ">86, dA[loss1:0.021,loss2:0.064] dB[loss1:0.050,loss2:0.408] g[loss1:17.994,loss2:18.011]\n",
      ">87, dA[loss1:0.042,loss2:0.033] dB[loss1:0.050,loss2:0.088] g[loss1:18.750,loss2:18.765]\n",
      ">88, dA[loss1:0.021,loss2:0.055] dB[loss1:0.046,loss2:0.042] g[loss1:19.707,loss2:19.623]\n",
      ">89, dA[loss1:0.069,loss2:0.117] dB[loss1:0.060,loss2:0.063] g[loss1:17.633,loss2:18.399]\n",
      ">90, dA[loss1:0.090,loss2:0.095] dB[loss1:0.032,loss2:0.069] g[loss1:18.013,loss2:18.328]\n",
      ">91, dA[loss1:0.069,loss2:0.063] dB[loss1:0.022,loss2:0.042] g[loss1:18.198,loss2:18.864]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">92, dA[loss1:0.025,loss2:0.054] dB[loss1:0.033,loss2:0.029] g[loss1:19.049,loss2:18.810]\n",
      ">93, dA[loss1:0.031,loss2:0.077] dB[loss1:0.046,loss2:0.013] g[loss1:18.565,loss2:18.824]\n",
      ">94, dA[loss1:0.020,loss2:0.031] dB[loss1:0.034,loss2:0.044] g[loss1:19.234,loss2:19.566]\n",
      ">95, dA[loss1:0.011,loss2:0.034] dB[loss1:0.072,loss2:0.055] g[loss1:18.708,loss2:19.103]\n",
      ">96, dA[loss1:0.021,loss2:0.049] dB[loss1:0.032,loss2:0.050] g[loss1:18.041,loss2:18.334]\n",
      ">97, dA[loss1:0.011,loss2:0.121] dB[loss1:0.054,loss2:0.035] g[loss1:17.968,loss2:18.488]\n",
      ">98, dA[loss1:0.010,loss2:0.032] dB[loss1:0.044,loss2:0.060] g[loss1:18.372,loss2:18.776]\n",
      ">99, dA[loss1:0.016,loss2:0.024] dB[loss1:0.059,loss2:0.094] g[loss1:17.561,loss2:18.709]\n",
      ">100, dA[loss1:0.025,loss2:0.044] dB[loss1:0.060,loss2:0.153] g[loss1:16.608,loss2:17.510]\n",
      ">101, dA[loss1:0.014,loss2:0.058] dB[loss1:0.060,loss2:0.104] g[loss1:18.281,loss2:18.665]\n",
      "model saved\n",
      ">102, dA[loss1:0.014,loss2:0.032] dB[loss1:0.075,loss2:0.023] g[loss1:16.455,loss2:17.715]\n",
      ">103, dA[loss1:0.019,loss2:0.039] dB[loss1:0.066,loss2:0.140] g[loss1:18.685,loss2:19.434]\n",
      ">104, dA[loss1:0.027,loss2:0.049] dB[loss1:0.040,loss2:0.056] g[loss1:18.890,loss2:19.009]\n",
      ">105, dA[loss1:0.027,loss2:0.046] dB[loss1:0.074,loss2:0.131] g[loss1:19.249,loss2:19.319]\n",
      ">106, dA[loss1:0.011,loss2:0.057] dB[loss1:0.060,loss2:0.094] g[loss1:17.361,loss2:18.124]\n",
      ">107, dA[loss1:0.016,loss2:0.135] dB[loss1:0.037,loss2:0.051] g[loss1:17.622,loss2:18.294]\n",
      ">108, dA[loss1:0.059,loss2:0.056] dB[loss1:0.049,loss2:0.100] g[loss1:17.405,loss2:18.527]\n",
      ">109, dA[loss1:0.028,loss2:0.060] dB[loss1:0.054,loss2:0.035] g[loss1:18.780,loss2:19.817]\n",
      ">110, dA[loss1:0.016,loss2:0.037] dB[loss1:0.050,loss2:0.041] g[loss1:18.553,loss2:19.151]\n",
      ">111, dA[loss1:0.011,loss2:0.037] dB[loss1:0.037,loss2:0.241] g[loss1:16.347,loss2:17.489]\n",
      ">112, dA[loss1:0.015,loss2:0.044] dB[loss1:0.042,loss2:0.078] g[loss1:18.502,loss2:18.537]\n",
      ">113, dA[loss1:0.030,loss2:0.027] dB[loss1:0.032,loss2:0.066] g[loss1:19.236,loss2:19.083]\n",
      ">114, dA[loss1:0.017,loss2:0.040] dB[loss1:0.038,loss2:0.075] g[loss1:17.902,loss2:18.210]\n",
      ">115, dA[loss1:0.022,loss2:0.022] dB[loss1:0.065,loss2:0.062] g[loss1:18.358,loss2:18.483]\n",
      ">116, dA[loss1:0.016,loss2:0.032] dB[loss1:0.030,loss2:0.066] g[loss1:18.038,loss2:18.410]\n",
      ">117, dA[loss1:0.018,loss2:0.112] dB[loss1:0.026,loss2:0.096] g[loss1:16.991,loss2:18.071]\n",
      ">118, dA[loss1:0.038,loss2:0.035] dB[loss1:0.038,loss2:0.024] g[loss1:18.257,loss2:18.617]\n",
      ">119, dA[loss1:0.020,loss2:0.023] dB[loss1:0.025,loss2:0.126] g[loss1:19.812,loss2:20.240]\n",
      ">120, dA[loss1:0.012,loss2:0.014] dB[loss1:0.046,loss2:0.062] g[loss1:18.605,loss2:18.877]\n",
      ">121, dA[loss1:0.016,loss2:0.028] dB[loss1:0.046,loss2:0.082] g[loss1:18.929,loss2:18.736]\n",
      ">122, dA[loss1:0.015,loss2:0.058] dB[loss1:0.019,loss2:0.144] g[loss1:16.881,loss2:17.718]\n",
      ">123, dA[loss1:0.023,loss2:0.063] dB[loss1:0.016,loss2:0.024] g[loss1:18.056,loss2:18.261]\n",
      ">124, dA[loss1:0.010,loss2:0.057] dB[loss1:0.070,loss2:0.038] g[loss1:19.144,loss2:19.447]\n",
      ">125, dA[loss1:0.012,loss2:0.076] dB[loss1:0.012,loss2:0.073] g[loss1:16.829,loss2:17.588]\n",
      ">126, dA[loss1:0.035,loss2:0.026] dB[loss1:0.031,loss2:0.054] g[loss1:17.701,loss2:18.364]\n",
      ">127, dA[loss1:0.032,loss2:0.055] dB[loss1:0.029,loss2:0.018] g[loss1:18.891,loss2:18.666]\n",
      ">128, dA[loss1:0.020,loss2:0.036] dB[loss1:0.034,loss2:0.045] g[loss1:18.306,loss2:18.742]\n",
      ">129, dA[loss1:0.024,loss2:0.135] dB[loss1:0.035,loss2:0.039] g[loss1:17.672,loss2:19.238]\n",
      ">130, dA[loss1:0.030,loss2:0.104] dB[loss1:0.048,loss2:0.144] g[loss1:16.209,loss2:17.508]\n",
      ">131, dA[loss1:0.032,loss2:0.059] dB[loss1:0.035,loss2:0.025] g[loss1:18.575,loss2:19.093]\n",
      ">132, dA[loss1:0.013,loss2:0.021] dB[loss1:0.028,loss2:0.055] g[loss1:19.546,loss2:19.419]\n",
      ">133, dA[loss1:0.014,loss2:0.034] dB[loss1:0.044,loss2:0.057] g[loss1:19.333,loss2:18.963]\n",
      ">134, dA[loss1:0.031,loss2:0.052] dB[loss1:0.134,loss2:0.034] g[loss1:17.917,loss2:18.360]\n",
      ">135, dA[loss1:0.015,loss2:0.022] dB[loss1:0.022,loss2:0.023] g[loss1:17.198,loss2:17.996]\n",
      ">136, dA[loss1:0.041,loss2:0.027] dB[loss1:0.054,loss2:0.047] g[loss1:18.260,loss2:18.697]\n",
      ">137, dA[loss1:0.016,loss2:0.042] dB[loss1:0.041,loss2:0.045] g[loss1:16.380,loss2:17.652]\n",
      ">138, dA[loss1:0.010,loss2:0.016] dB[loss1:0.017,loss2:0.038] g[loss1:18.582,loss2:18.667]\n",
      ">139, dA[loss1:0.010,loss2:0.035] dB[loss1:0.033,loss2:0.060] g[loss1:17.891,loss2:18.414]\n",
      ">140, dA[loss1:0.019,loss2:0.038] dB[loss1:0.043,loss2:0.043] g[loss1:17.604,loss2:18.115]\n",
      ">141, dA[loss1:0.009,loss2:0.023] dB[loss1:0.020,loss2:0.070] g[loss1:17.269,loss2:18.055]\n",
      ">142, dA[loss1:0.005,loss2:0.031] dB[loss1:0.015,loss2:0.057] g[loss1:17.870,loss2:18.203]\n",
      ">143, dA[loss1:0.007,loss2:0.021] dB[loss1:0.025,loss2:0.157] g[loss1:16.991,loss2:17.796]\n",
      ">144, dA[loss1:0.009,loss2:0.013] dB[loss1:0.031,loss2:0.110] g[loss1:17.350,loss2:18.077]\n",
      ">145, dA[loss1:0.018,loss2:0.023] dB[loss1:0.031,loss2:0.085] g[loss1:18.186,loss2:18.251]\n",
      ">146, dA[loss1:0.009,loss2:0.040] dB[loss1:0.031,loss2:0.050] g[loss1:18.367,loss2:18.614]\n",
      ">147, dA[loss1:0.016,loss2:0.033] dB[loss1:0.013,loss2:0.025] g[loss1:18.209,loss2:18.109]\n",
      ">148, dA[loss1:0.017,loss2:0.027] dB[loss1:0.028,loss2:0.080] g[loss1:17.835,loss2:17.957]\n",
      ">149, dA[loss1:0.010,loss2:0.035] dB[loss1:0.026,loss2:0.048] g[loss1:17.793,loss2:17.828]\n",
      ">150, dA[loss1:0.010,loss2:0.151] dB[loss1:0.023,loss2:0.064] g[loss1:18.279,loss2:18.085]\n",
      ">151, dA[loss1:0.049,loss2:0.024] dB[loss1:0.037,loss2:0.105] g[loss1:17.431,loss2:18.678]\n",
      ">152, dA[loss1:0.033,loss2:0.039] dB[loss1:0.028,loss2:0.015] g[loss1:17.682,loss2:18.842]\n",
      ">153, dA[loss1:0.010,loss2:0.037] dB[loss1:0.038,loss2:0.007] g[loss1:17.013,loss2:17.518]\n",
      ">154, dA[loss1:0.009,loss2:0.017] dB[loss1:0.025,loss2:0.089] g[loss1:16.740,loss2:17.734]\n",
      ">155, dA[loss1:0.005,loss2:0.017] dB[loss1:0.033,loss2:0.080] g[loss1:18.250,loss2:18.844]\n",
      ">156, dA[loss1:0.009,loss2:0.027] dB[loss1:0.057,loss2:0.100] g[loss1:16.888,loss2:17.388]\n",
      ">157, dA[loss1:0.007,loss2:0.048] dB[loss1:0.027,loss2:0.035] g[loss1:18.307,loss2:18.558]\n",
      ">158, dA[loss1:0.014,loss2:0.046] dB[loss1:0.033,loss2:0.079] g[loss1:18.315,loss2:18.860]\n",
      ">159, dA[loss1:0.020,loss2:0.024] dB[loss1:0.050,loss2:0.030] g[loss1:17.909,loss2:18.253]\n",
      ">160, dA[loss1:0.015,loss2:0.020] dB[loss1:0.024,loss2:0.062] g[loss1:18.378,loss2:18.123]\n",
      ">161, dA[loss1:0.024,loss2:0.017] dB[loss1:0.018,loss2:0.021] g[loss1:17.877,loss2:18.172]\n",
      ">162, dA[loss1:0.016,loss2:0.101] dB[loss1:0.017,loss2:0.026] g[loss1:17.380,loss2:17.608]\n",
      ">163, dA[loss1:0.028,loss2:0.037] dB[loss1:0.025,loss2:0.301] g[loss1:18.852,loss2:19.598]\n",
      ">164, dA[loss1:0.032,loss2:0.087] dB[loss1:0.048,loss2:0.055] g[loss1:16.757,loss2:17.731]\n",
      ">165, dA[loss1:0.024,loss2:0.053] dB[loss1:0.020,loss2:0.112] g[loss1:17.211,loss2:18.643]\n",
      ">166, dA[loss1:0.009,loss2:0.021] dB[loss1:0.027,loss2:0.060] g[loss1:17.611,loss2:18.492]\n",
      ">167, dA[loss1:0.005,loss2:0.011] dB[loss1:0.031,loss2:0.071] g[loss1:17.659,loss2:18.000]\n",
      ">168, dA[loss1:0.006,loss2:0.009] dB[loss1:0.029,loss2:0.037] g[loss1:18.411,loss2:18.680]\n",
      ">169, dA[loss1:0.013,loss2:0.023] dB[loss1:0.025,loss2:0.056] g[loss1:18.588,loss2:18.407]\n",
      ">170, dA[loss1:0.008,loss2:0.021] dB[loss1:0.018,loss2:0.038] g[loss1:19.038,loss2:18.999]\n",
      ">171, dA[loss1:0.008,loss2:0.027] dB[loss1:0.017,loss2:0.062] g[loss1:17.473,loss2:17.986]\n",
      ">172, dA[loss1:0.013,loss2:0.019] dB[loss1:0.024,loss2:0.037] g[loss1:18.510,loss2:18.759]\n",
      ">173, dA[loss1:0.004,loss2:0.067] dB[loss1:0.038,loss2:0.033] g[loss1:18.445,loss2:18.654]\n",
      ">174, dA[loss1:0.012,loss2:0.097] dB[loss1:0.016,loss2:0.051] g[loss1:16.754,loss2:17.242]\n",
      ">175, dA[loss1:0.018,loss2:0.039] dB[loss1:0.019,loss2:0.017] g[loss1:18.214,loss2:18.636]\n",
      ">176, dA[loss1:0.021,loss2:0.068] dB[loss1:0.039,loss2:0.031] g[loss1:18.638,loss2:19.390]\n",
      ">177, dA[loss1:0.038,loss2:0.020] dB[loss1:0.054,loss2:0.034] g[loss1:17.244,loss2:17.820]\n",
      ">178, dA[loss1:0.021,loss2:0.046] dB[loss1:0.021,loss2:0.020] g[loss1:16.036,loss2:16.813]\n",
      ">179, dA[loss1:0.026,loss2:0.011] dB[loss1:0.007,loss2:0.015] g[loss1:16.655,loss2:17.662]\n",
      ">180, dA[loss1:0.021,loss2:0.019] dB[loss1:0.030,loss2:0.092] g[loss1:17.300,loss2:18.112]\n",
      ">181, dA[loss1:0.033,loss2:0.013] dB[loss1:0.017,loss2:0.164] g[loss1:19.610,loss2:19.326]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">182, dA[loss1:0.014,loss2:0.020] dB[loss1:0.055,loss2:0.071] g[loss1:17.337,loss2:17.899]\n",
      ">183, dA[loss1:0.005,loss2:0.011] dB[loss1:0.025,loss2:0.039] g[loss1:17.714,loss2:18.420]\n",
      ">184, dA[loss1:0.009,loss2:0.025] dB[loss1:0.015,loss2:0.031] g[loss1:16.588,loss2:17.389]\n",
      ">185, dA[loss1:0.016,loss2:0.032] dB[loss1:0.029,loss2:0.103] g[loss1:18.176,loss2:17.923]\n",
      ">186, dA[loss1:0.019,loss2:0.012] dB[loss1:0.022,loss2:0.375] g[loss1:18.488,loss2:17.989]\n",
      ">187, dA[loss1:0.010,loss2:0.021] dB[loss1:0.033,loss2:0.141] g[loss1:16.868,loss2:17.240]\n",
      ">188, dA[loss1:0.020,loss2:0.057] dB[loss1:0.019,loss2:0.089] g[loss1:18.711,loss2:18.490]\n",
      ">189, dA[loss1:0.020,loss2:0.021] dB[loss1:0.033,loss2:0.066] g[loss1:17.535,loss2:17.796]\n",
      ">190, dA[loss1:0.012,loss2:0.024] dB[loss1:0.025,loss2:0.025] g[loss1:17.900,loss2:18.190]\n",
      ">191, dA[loss1:0.009,loss2:0.063] dB[loss1:0.071,loss2:0.021] g[loss1:18.639,loss2:18.963]\n",
      ">192, dA[loss1:0.011,loss2:0.041] dB[loss1:0.037,loss2:0.021] g[loss1:17.993,loss2:18.985]\n",
      ">193, dA[loss1:0.023,loss2:0.016] dB[loss1:0.031,loss2:0.012] g[loss1:16.912,loss2:17.743]\n",
      ">194, dA[loss1:0.004,loss2:0.012] dB[loss1:0.020,loss2:0.033] g[loss1:18.895,loss2:18.916]\n",
      ">195, dA[loss1:0.008,loss2:0.009] dB[loss1:0.034,loss2:0.025] g[loss1:18.515,loss2:18.682]\n",
      ">196, dA[loss1:0.005,loss2:0.014] dB[loss1:0.032,loss2:0.024] g[loss1:17.432,loss2:17.887]\n",
      ">197, dA[loss1:0.005,loss2:0.011] dB[loss1:0.025,loss2:0.025] g[loss1:16.297,loss2:17.552]\n",
      ">198, dA[loss1:0.006,loss2:0.010] dB[loss1:0.031,loss2:0.035] g[loss1:17.091,loss2:17.865]\n",
      ">199, dA[loss1:0.004,loss2:0.059] dB[loss1:0.025,loss2:0.008] g[loss1:16.747,loss2:17.372]\n",
      ">200, dA[loss1:0.012,loss2:0.018] dB[loss1:0.018,loss2:0.094] g[loss1:18.106,loss2:18.434]\n",
      ">201, dA[loss1:0.004,loss2:0.065] dB[loss1:0.021,loss2:0.059] g[loss1:18.099,loss2:17.988]\n",
      "model saved\n",
      ">202, dA[loss1:0.032,loss2:0.035] dB[loss1:0.017,loss2:0.028] g[loss1:18.151,loss2:18.598]\n",
      ">203, dA[loss1:0.041,loss2:0.024] dB[loss1:0.015,loss2:0.025] g[loss1:18.041,loss2:18.409]\n",
      ">204, dA[loss1:0.034,loss2:0.015] dB[loss1:0.026,loss2:0.028] g[loss1:17.549,loss2:17.945]\n",
      ">205, dA[loss1:0.014,loss2:0.130] dB[loss1:0.037,loss2:0.038] g[loss1:17.500,loss2:18.057]\n",
      ">206, dA[loss1:0.024,loss2:0.060] dB[loss1:0.013,loss2:0.032] g[loss1:16.339,loss2:17.910]\n",
      ">207, dA[loss1:0.034,loss2:0.024] dB[loss1:0.027,loss2:0.040] g[loss1:17.591,loss2:17.953]\n",
      ">208, dA[loss1:0.036,loss2:0.054] dB[loss1:0.027,loss2:0.044] g[loss1:18.306,loss2:18.217]\n",
      ">209, dA[loss1:0.004,loss2:0.057] dB[loss1:0.013,loss2:0.052] g[loss1:17.270,loss2:17.745]\n",
      ">210, dA[loss1:0.018,loss2:0.113] dB[loss1:0.025,loss2:0.029] g[loss1:17.199,loss2:17.769]\n",
      ">211, dA[loss1:0.024,loss2:0.049] dB[loss1:0.053,loss2:0.039] g[loss1:19.192,loss2:18.738]\n",
      ">212, dA[loss1:0.026,loss2:0.023] dB[loss1:0.017,loss2:0.034] g[loss1:17.708,loss2:19.134]\n",
      ">213, dA[loss1:0.014,loss2:0.193] dB[loss1:0.030,loss2:0.050] g[loss1:17.675,loss2:18.400]\n",
      ">214, dA[loss1:0.016,loss2:0.928] dB[loss1:0.018,loss2:0.072] g[loss1:18.011,loss2:18.988]\n",
      ">215, dA[loss1:0.158,loss2:0.693] dB[loss1:0.019,loss2:0.044] g[loss1:17.594,loss2:18.986]\n",
      ">216, dA[loss1:0.064,loss2:0.159] dB[loss1:0.019,loss2:0.260] g[loss1:16.004,loss2:17.366]\n",
      ">217, dA[loss1:0.009,loss2:0.175] dB[loss1:0.054,loss2:0.105] g[loss1:19.604,loss2:18.841]\n",
      ">218, dA[loss1:0.029,loss2:0.042] dB[loss1:0.027,loss2:0.064] g[loss1:17.777,loss2:17.788]\n",
      ">219, dA[loss1:0.016,loss2:0.087] dB[loss1:0.026,loss2:0.043] g[loss1:17.115,loss2:17.644]\n",
      ">220, dA[loss1:0.018,loss2:0.027] dB[loss1:0.025,loss2:0.040] g[loss1:18.473,loss2:18.416]\n",
      ">221, dA[loss1:0.007,loss2:0.017] dB[loss1:0.023,loss2:0.070] g[loss1:19.077,loss2:18.866]\n",
      ">222, dA[loss1:0.008,loss2:0.010] dB[loss1:0.039,loss2:0.043] g[loss1:17.251,loss2:17.988]\n",
      ">223, dA[loss1:0.005,loss2:0.029] dB[loss1:0.021,loss2:0.019] g[loss1:17.518,loss2:18.132]\n",
      ">224, dA[loss1:0.005,loss2:0.010] dB[loss1:0.021,loss2:0.031] g[loss1:16.940,loss2:17.411]\n",
      ">225, dA[loss1:0.003,loss2:0.009] dB[loss1:0.011,loss2:0.012] g[loss1:17.755,loss2:18.103]\n",
      ">226, dA[loss1:0.006,loss2:0.015] dB[loss1:0.007,loss2:0.014] g[loss1:17.173,loss2:17.646]\n",
      ">227, dA[loss1:0.006,loss2:0.022] dB[loss1:0.003,loss2:0.033] g[loss1:16.744,loss2:17.226]\n",
      ">228, dA[loss1:0.005,loss2:0.009] dB[loss1:0.011,loss2:0.021] g[loss1:18.342,loss2:18.230]\n",
      ">229, dA[loss1:0.009,loss2:0.011] dB[loss1:0.023,loss2:0.022] g[loss1:17.883,loss2:17.852]\n",
      ">230, dA[loss1:0.003,loss2:0.022] dB[loss1:0.030,loss2:0.071] g[loss1:17.576,loss2:17.879]\n",
      ">231, dA[loss1:0.006,loss2:0.020] dB[loss1:0.019,loss2:0.051] g[loss1:17.673,loss2:17.900]\n",
      ">232, dA[loss1:0.006,loss2:0.025] dB[loss1:0.008,loss2:0.028] g[loss1:17.400,loss2:17.537]\n",
      ">233, dA[loss1:0.007,loss2:0.020] dB[loss1:0.014,loss2:0.024] g[loss1:17.926,loss2:18.284]\n",
      ">234, dA[loss1:0.010,loss2:0.031] dB[loss1:0.013,loss2:0.030] g[loss1:17.439,loss2:18.167]\n",
      ">235, dA[loss1:0.006,loss2:0.019] dB[loss1:0.013,loss2:0.008] g[loss1:18.217,loss2:17.998]\n",
      ">236, dA[loss1:0.013,loss2:0.015] dB[loss1:0.006,loss2:0.016] g[loss1:17.645,loss2:18.175]\n",
      ">237, dA[loss1:0.006,loss2:0.023] dB[loss1:0.019,loss2:0.074] g[loss1:17.189,loss2:18.346]\n",
      ">238, dA[loss1:0.007,loss2:0.011] dB[loss1:0.020,loss2:0.061] g[loss1:17.536,loss2:17.870]\n",
      ">239, dA[loss1:0.006,loss2:0.006] dB[loss1:0.035,loss2:0.116] g[loss1:16.702,loss2:16.735]\n",
      ">240, dA[loss1:0.003,loss2:0.040] dB[loss1:0.019,loss2:0.032] g[loss1:18.082,loss2:18.216]\n",
      ">241, dA[loss1:0.006,loss2:0.017] dB[loss1:0.010,loss2:0.047] g[loss1:17.903,loss2:18.039]\n",
      ">242, dA[loss1:0.009,loss2:0.041] dB[loss1:0.008,loss2:0.028] g[loss1:17.697,loss2:17.812]\n",
      ">243, dA[loss1:0.031,loss2:0.090] dB[loss1:0.015,loss2:0.009] g[loss1:16.583,loss2:18.129]\n",
      ">244, dA[loss1:0.021,loss2:0.016] dB[loss1:0.011,loss2:0.012] g[loss1:17.759,loss2:18.189]\n",
      ">245, dA[loss1:0.007,loss2:0.012] dB[loss1:0.019,loss2:0.014] g[loss1:17.703,loss2:18.104]\n",
      ">246, dA[loss1:0.002,loss2:0.008] dB[loss1:0.011,loss2:0.019] g[loss1:16.744,loss2:17.330]\n",
      ">247, dA[loss1:0.004,loss2:0.067] dB[loss1:0.017,loss2:0.025] g[loss1:16.391,loss2:17.343]\n",
      ">248, dA[loss1:0.024,loss2:0.047] dB[loss1:0.028,loss2:0.035] g[loss1:17.093,loss2:17.503]\n",
      ">249, dA[loss1:0.017,loss2:0.018] dB[loss1:0.022,loss2:0.041] g[loss1:18.382,loss2:18.483]\n",
      ">250, dA[loss1:0.019,loss2:0.006] dB[loss1:0.018,loss2:0.021] g[loss1:18.043,loss2:18.250]\n",
      ">251, dA[loss1:0.011,loss2:0.024] dB[loss1:0.014,loss2:0.028] g[loss1:16.706,loss2:17.345]\n",
      ">252, dA[loss1:0.003,loss2:0.024] dB[loss1:0.009,loss2:0.035] g[loss1:17.588,loss2:17.602]\n",
      ">253, dA[loss1:0.010,loss2:0.019] dB[loss1:0.010,loss2:0.023] g[loss1:17.313,loss2:17.686]\n",
      ">254, dA[loss1:0.007,loss2:0.005] dB[loss1:0.013,loss2:0.022] g[loss1:17.245,loss2:17.844]\n",
      ">255, dA[loss1:0.006,loss2:0.013] dB[loss1:0.015,loss2:0.024] g[loss1:17.870,loss2:17.760]\n",
      ">256, dA[loss1:0.006,loss2:0.047] dB[loss1:0.012,loss2:0.040] g[loss1:17.005,loss2:17.536]\n",
      ">257, dA[loss1:0.003,loss2:0.040] dB[loss1:0.022,loss2:0.036] g[loss1:17.414,loss2:17.316]\n",
      ">258, dA[loss1:0.006,loss2:0.009] dB[loss1:0.016,loss2:0.084] g[loss1:16.798,loss2:17.115]\n",
      ">259, dA[loss1:0.015,loss2:0.019] dB[loss1:0.033,loss2:0.030] g[loss1:17.544,loss2:18.619]\n",
      ">260, dA[loss1:0.016,loss2:0.054] dB[loss1:0.013,loss2:0.034] g[loss1:17.204,loss2:17.837]\n",
      ">261, dA[loss1:0.005,loss2:0.016] dB[loss1:0.010,loss2:0.056] g[loss1:17.614,loss2:18.217]\n",
      ">262, dA[loss1:0.008,loss2:0.013] dB[loss1:0.023,loss2:0.026] g[loss1:18.126,loss2:18.085]\n",
      ">263, dA[loss1:0.005,loss2:0.016] dB[loss1:0.043,loss2:0.120] g[loss1:16.179,loss2:16.640]\n",
      ">264, dA[loss1:0.004,loss2:0.021] dB[loss1:0.044,loss2:0.058] g[loss1:16.935,loss2:17.539]\n",
      ">265, dA[loss1:0.005,loss2:0.026] dB[loss1:0.028,loss2:0.048] g[loss1:18.436,loss2:18.512]\n",
      ">266, dA[loss1:0.015,loss2:0.072] dB[loss1:0.071,loss2:0.078] g[loss1:16.935,loss2:16.985]\n",
      ">267, dA[loss1:0.023,loss2:0.015] dB[loss1:0.030,loss2:0.020] g[loss1:17.743,loss2:17.637]\n",
      ">268, dA[loss1:0.007,loss2:0.010] dB[loss1:0.010,loss2:0.089] g[loss1:17.623,loss2:17.511]\n",
      ">269, dA[loss1:0.007,loss2:0.047] dB[loss1:0.016,loss2:0.020] g[loss1:17.498,loss2:17.152]\n",
      ">270, dA[loss1:0.039,loss2:0.030] dB[loss1:0.014,loss2:0.020] g[loss1:17.626,loss2:17.906]\n",
      ">271, dA[loss1:0.008,loss2:0.033] dB[loss1:0.008,loss2:0.011] g[loss1:17.740,loss2:18.210]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">272, dA[loss1:0.020,loss2:0.018] dB[loss1:0.012,loss2:0.030] g[loss1:17.681,loss2:17.959]\n",
      ">273, dA[loss1:0.007,loss2:0.007] dB[loss1:0.015,loss2:0.037] g[loss1:17.780,loss2:17.840]\n",
      ">274, dA[loss1:0.005,loss2:0.027] dB[loss1:0.021,loss2:0.061] g[loss1:17.170,loss2:17.555]\n",
      ">275, dA[loss1:0.012,loss2:0.121] dB[loss1:0.018,loss2:0.018] g[loss1:16.561,loss2:17.127]\n",
      ">276, dA[loss1:0.030,loss2:0.792] dB[loss1:0.019,loss2:0.079] g[loss1:16.654,loss2:18.663]\n",
      ">277, dA[loss1:0.179,loss2:2.089] dB[loss1:0.031,loss2:0.044] g[loss1:17.927,loss2:20.292]\n",
      ">278, dA[loss1:0.352,loss2:0.239] dB[loss1:0.032,loss2:0.017] g[loss1:17.943,loss2:18.951]\n",
      ">279, dA[loss1:0.076,loss2:0.055] dB[loss1:0.021,loss2:0.016] g[loss1:18.014,loss2:18.149]\n",
      ">280, dA[loss1:0.062,loss2:0.049] dB[loss1:0.023,loss2:0.014] g[loss1:16.522,loss2:17.092]\n",
      ">281, dA[loss1:0.050,loss2:0.030] dB[loss1:0.022,loss2:0.048] g[loss1:18.950,loss2:19.320]\n",
      ">282, dA[loss1:0.016,loss2:0.045] dB[loss1:0.013,loss2:0.052] g[loss1:16.425,loss2:17.190]\n",
      ">283, dA[loss1:0.009,loss2:0.037] dB[loss1:0.023,loss2:0.032] g[loss1:17.221,loss2:17.428]\n",
      ">284, dA[loss1:0.004,loss2:0.031] dB[loss1:0.027,loss2:0.013] g[loss1:17.838,loss2:17.939]\n",
      ">285, dA[loss1:0.024,loss2:0.026] dB[loss1:0.012,loss2:0.048] g[loss1:16.885,loss2:17.596]\n",
      ">286, dA[loss1:0.014,loss2:0.020] dB[loss1:0.022,loss2:0.030] g[loss1:17.848,loss2:17.916]\n",
      ">287, dA[loss1:0.017,loss2:0.009] dB[loss1:0.018,loss2:0.019] g[loss1:17.833,loss2:17.850]\n",
      ">288, dA[loss1:0.008,loss2:0.005] dB[loss1:0.013,loss2:0.016] g[loss1:16.906,loss2:17.349]\n",
      ">289, dA[loss1:0.002,loss2:0.005] dB[loss1:0.012,loss2:0.054] g[loss1:18.069,loss2:18.107]\n",
      ">290, dA[loss1:0.008,loss2:0.018] dB[loss1:0.010,loss2:0.053] g[loss1:17.414,loss2:18.079]\n",
      ">291, dA[loss1:0.007,loss2:0.005] dB[loss1:0.009,loss2:0.086] g[loss1:18.742,loss2:18.501]\n",
      ">292, dA[loss1:0.005,loss2:0.008] dB[loss1:0.011,loss2:0.032] g[loss1:17.220,loss2:17.626]\n",
      ">293, dA[loss1:0.005,loss2:0.098] dB[loss1:0.019,loss2:0.028] g[loss1:17.467,loss2:17.586]\n",
      ">294, dA[loss1:0.017,loss2:0.029] dB[loss1:0.011,loss2:0.076] g[loss1:17.278,loss2:17.738]\n",
      ">295, dA[loss1:0.012,loss2:0.071] dB[loss1:0.016,loss2:0.055] g[loss1:16.400,loss2:16.988]\n",
      ">296, dA[loss1:0.037,loss2:0.023] dB[loss1:0.049,loss2:0.048] g[loss1:16.588,loss2:17.242]\n",
      ">297, dA[loss1:0.004,loss2:0.009] dB[loss1:0.018,loss2:0.025] g[loss1:17.291,loss2:17.780]\n",
      ">298, dA[loss1:0.013,loss2:0.025] dB[loss1:0.027,loss2:0.056] g[loss1:16.747,loss2:17.174]\n",
      ">299, dA[loss1:0.006,loss2:0.047] dB[loss1:0.026,loss2:0.044] g[loss1:17.077,loss2:17.337]\n",
      ">300, dA[loss1:0.005,loss2:0.015] dB[loss1:0.017,loss2:0.025] g[loss1:17.107,loss2:17.317]\n",
      ">301, dA[loss1:0.009,loss2:0.008] dB[loss1:0.006,loss2:0.023] g[loss1:18.025,loss2:18.280]\n",
      "model saved\n",
      ">302, dA[loss1:0.003,loss2:0.010] dB[loss1:0.025,loss2:0.049] g[loss1:17.342,loss2:17.636]\n",
      ">303, dA[loss1:0.009,loss2:0.008] dB[loss1:0.020,loss2:0.062] g[loss1:17.340,loss2:17.996]\n",
      ">304, dA[loss1:0.003,loss2:0.006] dB[loss1:0.024,loss2:0.053] g[loss1:16.188,loss2:16.974]\n",
      ">305, dA[loss1:0.003,loss2:0.006] dB[loss1:0.010,loss2:0.048] g[loss1:17.139,loss2:17.331]\n",
      ">306, dA[loss1:0.006,loss2:0.004] dB[loss1:0.009,loss2:0.028] g[loss1:16.395,loss2:17.004]\n",
      ">307, dA[loss1:0.004,loss2:0.006] dB[loss1:0.012,loss2:0.062] g[loss1:16.686,loss2:17.903]\n",
      ">308, dA[loss1:0.004,loss2:0.004] dB[loss1:0.010,loss2:0.024] g[loss1:16.656,loss2:17.033]\n",
      ">309, dA[loss1:0.003,loss2:0.006] dB[loss1:0.017,loss2:0.071] g[loss1:17.625,loss2:17.825]\n",
      ">310, dA[loss1:0.002,loss2:0.004] dB[loss1:0.010,loss2:0.007] g[loss1:17.353,loss2:17.600]\n",
      ">311, dA[loss1:0.001,loss2:0.024] dB[loss1:0.014,loss2:0.058] g[loss1:17.272,loss2:17.530]\n",
      ">312, dA[loss1:0.011,loss2:0.009] dB[loss1:0.033,loss2:0.028] g[loss1:17.529,loss2:17.845]\n",
      ">313, dA[loss1:0.004,loss2:0.003] dB[loss1:0.019,loss2:0.029] g[loss1:17.392,loss2:17.684]\n",
      ">314, dA[loss1:0.003,loss2:0.019] dB[loss1:0.023,loss2:0.032] g[loss1:16.209,loss2:17.000]\n",
      ">315, dA[loss1:0.002,loss2:0.015] dB[loss1:0.012,loss2:0.019] g[loss1:15.352,loss2:16.388]\n",
      ">316, dA[loss1:0.002,loss2:0.020] dB[loss1:0.010,loss2:0.043] g[loss1:16.671,loss2:17.283]\n",
      ">317, dA[loss1:0.003,loss2:0.022] dB[loss1:0.015,loss2:0.019] g[loss1:17.279,loss2:17.543]\n",
      ">318, dA[loss1:0.011,loss2:0.080] dB[loss1:0.012,loss2:0.016] g[loss1:17.193,loss2:17.662]\n",
      ">319, dA[loss1:0.005,loss2:0.030] dB[loss1:0.010,loss2:0.017] g[loss1:17.207,loss2:17.487]\n",
      ">320, dA[loss1:0.006,loss2:0.013] dB[loss1:0.007,loss2:0.044] g[loss1:17.512,loss2:17.703]\n",
      ">321, dA[loss1:0.010,loss2:0.008] dB[loss1:0.010,loss2:0.027] g[loss1:15.911,loss2:16.527]\n",
      ">322, dA[loss1:0.004,loss2:0.004] dB[loss1:0.008,loss2:0.058] g[loss1:17.288,loss2:17.494]\n",
      ">323, dA[loss1:0.003,loss2:0.008] dB[loss1:0.008,loss2:0.026] g[loss1:18.159,loss2:18.456]\n",
      ">324, dA[loss1:0.003,loss2:0.014] dB[loss1:0.012,loss2:0.053] g[loss1:17.551,loss2:18.213]\n",
      ">325, dA[loss1:0.003,loss2:0.065] dB[loss1:0.013,loss2:0.029] g[loss1:16.934,loss2:17.282]\n",
      ">326, dA[loss1:0.011,loss2:0.013] dB[loss1:0.013,loss2:0.068] g[loss1:15.928,loss2:16.718]\n",
      ">327, dA[loss1:0.002,loss2:0.012] dB[loss1:0.037,loss2:0.037] g[loss1:16.343,loss2:16.691]\n",
      ">328, dA[loss1:0.004,loss2:0.048] dB[loss1:0.016,loss2:0.018] g[loss1:18.121,loss2:17.901]\n",
      ">329, dA[loss1:0.009,loss2:0.024] dB[loss1:0.011,loss2:0.013] g[loss1:15.474,loss2:16.219]\n",
      ">330, dA[loss1:0.008,loss2:0.030] dB[loss1:0.007,loss2:0.008] g[loss1:17.342,loss2:17.377]\n",
      ">331, dA[loss1:0.006,loss2:0.006] dB[loss1:0.009,loss2:0.022] g[loss1:17.610,loss2:17.771]\n",
      ">332, dA[loss1:0.003,loss2:0.007] dB[loss1:0.008,loss2:0.022] g[loss1:17.019,loss2:17.224]\n",
      ">333, dA[loss1:0.007,loss2:0.013] dB[loss1:0.011,loss2:0.017] g[loss1:16.793,loss2:17.062]\n",
      ">334, dA[loss1:0.005,loss2:0.010] dB[loss1:0.009,loss2:0.012] g[loss1:14.834,loss2:16.041]\n",
      ">335, dA[loss1:0.002,loss2:0.013] dB[loss1:0.011,loss2:0.009] g[loss1:15.816,loss2:16.666]\n",
      ">336, dA[loss1:0.002,loss2:0.020] dB[loss1:0.007,loss2:0.025] g[loss1:15.817,loss2:16.555]\n",
      ">337, dA[loss1:0.007,loss2:0.013] dB[loss1:0.013,loss2:0.038] g[loss1:17.027,loss2:17.696]\n",
      ">338, dA[loss1:0.005,loss2:0.093] dB[loss1:0.026,loss2:0.017] g[loss1:17.281,loss2:17.533]\n",
      ">339, dA[loss1:0.014,loss2:0.024] dB[loss1:0.011,loss2:0.018] g[loss1:17.832,loss2:17.924]\n",
      ">340, dA[loss1:0.003,loss2:0.011] dB[loss1:0.013,loss2:0.019] g[loss1:16.969,loss2:16.867]\n",
      ">341, dA[loss1:0.006,loss2:0.007] dB[loss1:0.010,loss2:0.037] g[loss1:15.610,loss2:16.442]\n",
      ">342, dA[loss1:0.004,loss2:0.069] dB[loss1:0.011,loss2:0.017] g[loss1:16.720,loss2:16.714]\n",
      ">343, dA[loss1:0.019,loss2:0.029] dB[loss1:0.011,loss2:0.011] g[loss1:16.215,loss2:16.796]\n",
      ">344, dA[loss1:0.017,loss2:0.021] dB[loss1:0.012,loss2:0.017] g[loss1:16.796,loss2:17.596]\n",
      ">345, dA[loss1:0.013,loss2:0.009] dB[loss1:0.014,loss2:0.014] g[loss1:18.311,loss2:18.006]\n",
      ">346, dA[loss1:0.005,loss2:0.011] dB[loss1:0.008,loss2:0.018] g[loss1:16.732,loss2:17.244]\n",
      ">347, dA[loss1:0.005,loss2:0.006] dB[loss1:0.008,loss2:0.010] g[loss1:17.599,loss2:17.650]\n",
      ">348, dA[loss1:0.006,loss2:0.003] dB[loss1:0.009,loss2:0.020] g[loss1:15.671,loss2:16.112]\n",
      ">349, dA[loss1:0.007,loss2:0.014] dB[loss1:0.007,loss2:0.015] g[loss1:17.298,loss2:17.904]\n",
      ">350, dA[loss1:0.008,loss2:0.015] dB[loss1:0.006,loss2:0.079] g[loss1:16.120,loss2:16.558]\n",
      ">351, dA[loss1:0.010,loss2:0.012] dB[loss1:0.010,loss2:0.032] g[loss1:15.970,loss2:16.996]\n",
      ">352, dA[loss1:0.007,loss2:0.008] dB[loss1:0.010,loss2:0.006] g[loss1:17.972,loss2:17.858]\n",
      ">353, dA[loss1:0.002,loss2:0.003] dB[loss1:0.016,loss2:0.028] g[loss1:16.194,loss2:16.952]\n",
      ">354, dA[loss1:0.002,loss2:0.046] dB[loss1:0.010,loss2:0.008] g[loss1:17.949,loss2:18.110]\n",
      ">355, dA[loss1:0.006,loss2:0.006] dB[loss1:0.012,loss2:0.004] g[loss1:17.389,loss2:17.665]\n",
      ">356, dA[loss1:0.004,loss2:0.005] dB[loss1:0.007,loss2:0.006] g[loss1:16.999,loss2:17.294]\n",
      ">357, dA[loss1:0.002,loss2:0.007] dB[loss1:0.012,loss2:0.016] g[loss1:16.388,loss2:17.067]\n",
      ">358, dA[loss1:0.002,loss2:0.004] dB[loss1:0.006,loss2:0.023] g[loss1:16.822,loss2:17.291]\n",
      ">359, dA[loss1:0.003,loss2:0.008] dB[loss1:0.009,loss2:0.041] g[loss1:15.995,loss2:16.755]\n",
      ">360, dA[loss1:0.003,loss2:0.008] dB[loss1:0.014,loss2:0.022] g[loss1:16.787,loss2:17.220]\n",
      ">361, dA[loss1:0.003,loss2:0.012] dB[loss1:0.010,loss2:0.035] g[loss1:16.658,loss2:16.936]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">362, dA[loss1:0.007,loss2:0.006] dB[loss1:0.013,loss2:0.028] g[loss1:17.085,loss2:17.318]\n",
      ">363, dA[loss1:0.005,loss2:0.003] dB[loss1:0.016,loss2:0.013] g[loss1:17.089,loss2:17.285]\n",
      ">364, dA[loss1:0.002,loss2:0.008] dB[loss1:0.011,loss2:0.018] g[loss1:16.716,loss2:17.211]\n",
      ">365, dA[loss1:0.006,loss2:0.021] dB[loss1:0.011,loss2:0.027] g[loss1:16.287,loss2:16.912]\n",
      ">366, dA[loss1:0.004,loss2:0.026] dB[loss1:0.011,loss2:0.018] g[loss1:17.517,loss2:17.414]\n",
      ">367, dA[loss1:0.007,loss2:0.012] dB[loss1:0.013,loss2:0.009] g[loss1:16.701,loss2:17.442]\n",
      ">368, dA[loss1:0.004,loss2:0.010] dB[loss1:0.005,loss2:0.023] g[loss1:15.255,loss2:16.072]\n",
      ">369, dA[loss1:0.011,loss2:0.003] dB[loss1:0.017,loss2:0.043] g[loss1:17.179,loss2:17.460]\n",
      ">370, dA[loss1:0.002,loss2:0.008] dB[loss1:0.010,loss2:0.009] g[loss1:16.855,loss2:17.187]\n",
      ">371, dA[loss1:0.003,loss2:0.002] dB[loss1:0.019,loss2:0.041] g[loss1:16.620,loss2:16.783]\n",
      ">372, dA[loss1:0.003,loss2:0.002] dB[loss1:0.015,loss2:0.014] g[loss1:16.755,loss2:17.032]\n",
      ">373, dA[loss1:0.003,loss2:0.007] dB[loss1:0.008,loss2:0.011] g[loss1:16.873,loss2:16.644]\n",
      ">374, dA[loss1:0.002,loss2:0.003] dB[loss1:0.011,loss2:0.006] g[loss1:16.265,loss2:16.643]\n",
      ">375, dA[loss1:0.001,loss2:0.006] dB[loss1:0.008,loss2:0.004] g[loss1:16.815,loss2:16.994]\n",
      ">376, dA[loss1:0.004,loss2:0.037] dB[loss1:0.009,loss2:0.008] g[loss1:16.307,loss2:16.306]\n",
      ">377, dA[loss1:0.010,loss2:0.006] dB[loss1:0.010,loss2:0.020] g[loss1:15.608,loss2:16.178]\n",
      ">378, dA[loss1:0.003,loss2:0.035] dB[loss1:0.011,loss2:0.004] g[loss1:16.853,loss2:16.989]\n",
      ">379, dA[loss1:0.002,loss2:0.027] dB[loss1:0.009,loss2:0.003] g[loss1:17.268,loss2:17.472]\n",
      ">380, dA[loss1:0.001,loss2:0.021] dB[loss1:0.005,loss2:0.015] g[loss1:17.312,loss2:17.314]\n",
      ">381, dA[loss1:0.002,loss2:0.007] dB[loss1:0.008,loss2:0.005] g[loss1:16.407,loss2:16.678]\n",
      ">382, dA[loss1:0.001,loss2:0.005] dB[loss1:0.005,loss2:0.004] g[loss1:17.101,loss2:17.322]\n",
      ">383, dA[loss1:0.002,loss2:0.046] dB[loss1:0.009,loss2:0.004] g[loss1:16.961,loss2:17.171]\n",
      ">384, dA[loss1:0.002,loss2:0.027] dB[loss1:0.006,loss2:0.003] g[loss1:17.370,loss2:17.370]\n",
      ">385, dA[loss1:0.006,loss2:0.006] dB[loss1:0.003,loss2:0.002] g[loss1:17.248,loss2:17.659]\n",
      ">386, dA[loss1:0.002,loss2:0.004] dB[loss1:0.012,loss2:0.004] g[loss1:17.045,loss2:17.812]\n",
      ">387, dA[loss1:0.003,loss2:0.005] dB[loss1:0.004,loss2:0.014] g[loss1:16.838,loss2:17.180]\n",
      ">388, dA[loss1:0.003,loss2:0.004] dB[loss1:0.006,loss2:0.004] g[loss1:16.433,loss2:17.010]\n",
      ">389, dA[loss1:0.001,loss2:0.004] dB[loss1:0.006,loss2:0.003] g[loss1:17.335,loss2:17.647]\n",
      ">390, dA[loss1:0.002,loss2:0.005] dB[loss1:0.005,loss2:0.001] g[loss1:17.223,loss2:17.574]\n",
      ">391, dA[loss1:0.002,loss2:0.008] dB[loss1:0.004,loss2:0.063] g[loss1:16.186,loss2:16.632]\n",
      ">392, dA[loss1:0.001,loss2:0.007] dB[loss1:0.008,loss2:0.035] g[loss1:16.125,loss2:16.655]\n",
      ">393, dA[loss1:0.003,loss2:0.010] dB[loss1:0.006,loss2:0.010] g[loss1:16.336,loss2:16.627]\n",
      ">394, dA[loss1:0.002,loss2:0.008] dB[loss1:0.008,loss2:0.013] g[loss1:17.194,loss2:17.502]\n",
      ">395, dA[loss1:0.001,loss2:0.007] dB[loss1:0.008,loss2:0.064] g[loss1:17.675,loss2:17.735]\n",
      ">396, dA[loss1:0.007,loss2:0.014] dB[loss1:0.007,loss2:0.051] g[loss1:16.584,loss2:16.751]\n",
      ">397, dA[loss1:0.004,loss2:0.011] dB[loss1:0.007,loss2:0.017] g[loss1:16.697,loss2:16.896]\n",
      ">398, dA[loss1:0.003,loss2:0.004] dB[loss1:0.015,loss2:0.014] g[loss1:17.226,loss2:17.159]\n",
      ">399, dA[loss1:0.002,loss2:0.023] dB[loss1:0.013,loss2:0.007] g[loss1:15.115,loss2:15.824]\n",
      ">400, dA[loss1:0.002,loss2:0.007] dB[loss1:0.007,loss2:0.003] g[loss1:16.409,loss2:16.821]\n",
      ">401, dA[loss1:0.004,loss2:0.005] dB[loss1:0.010,loss2:0.005] g[loss1:16.914,loss2:17.214]\n",
      "model saved\n",
      ">402, dA[loss1:0.001,loss2:0.014] dB[loss1:0.007,loss2:0.007] g[loss1:16.600,loss2:16.829]\n",
      ">403, dA[loss1:0.001,loss2:0.008] dB[loss1:0.005,loss2:0.015] g[loss1:16.577,loss2:17.063]\n",
      ">404, dA[loss1:0.002,loss2:0.002] dB[loss1:0.014,loss2:0.224] g[loss1:16.529,loss2:16.673]\n",
      ">405, dA[loss1:0.003,loss2:0.002] dB[loss1:0.013,loss2:0.121] g[loss1:17.864,loss2:17.420]\n",
      ">406, dA[loss1:0.001,loss2:0.005] dB[loss1:0.091,loss2:0.024] g[loss1:17.452,loss2:17.746]\n",
      ">407, dA[loss1:0.002,loss2:0.007] dB[loss1:0.054,loss2:0.015] g[loss1:16.148,loss2:16.489]\n",
      ">408, dA[loss1:0.004,loss2:0.006] dB[loss1:0.022,loss2:0.034] g[loss1:16.173,loss2:17.506]\n",
      ">409, dA[loss1:0.002,loss2:0.004] dB[loss1:0.007,loss2:0.015] g[loss1:17.215,loss2:17.078]\n",
      ">410, dA[loss1:0.001,loss2:0.008] dB[loss1:0.010,loss2:0.027] g[loss1:16.763,loss2:17.000]\n",
      ">411, dA[loss1:0.001,loss2:0.004] dB[loss1:0.008,loss2:0.023] g[loss1:15.337,loss2:16.182]\n",
      ">412, dA[loss1:0.001,loss2:0.006] dB[loss1:0.037,loss2:0.029] g[loss1:16.879,loss2:16.898]\n",
      ">413, dA[loss1:0.006,loss2:0.003] dB[loss1:0.037,loss2:0.005] g[loss1:16.074,loss2:16.666]\n",
      ">414, dA[loss1:0.002,loss2:0.008] dB[loss1:0.010,loss2:0.010] g[loss1:17.281,loss2:17.266]\n",
      ">415, dA[loss1:0.002,loss2:0.013] dB[loss1:0.010,loss2:0.016] g[loss1:15.311,loss2:16.048]\n",
      ">416, dA[loss1:0.004,loss2:0.011] dB[loss1:0.007,loss2:0.020] g[loss1:15.946,loss2:16.289]\n",
      ">417, dA[loss1:0.005,loss2:0.009] dB[loss1:0.009,loss2:0.073] g[loss1:17.093,loss2:17.426]\n",
      ">418, dA[loss1:0.001,loss2:0.008] dB[loss1:0.008,loss2:0.023] g[loss1:16.054,loss2:16.522]\n",
      ">419, dA[loss1:0.005,loss2:0.007] dB[loss1:0.016,loss2:0.009] g[loss1:16.569,loss2:16.726]\n",
      ">420, dA[loss1:0.003,loss2:0.015] dB[loss1:0.008,loss2:0.030] g[loss1:16.619,loss2:16.829]\n",
      ">421, dA[loss1:0.004,loss2:0.006] dB[loss1:0.004,loss2:0.079] g[loss1:17.104,loss2:17.130]\n",
      ">422, dA[loss1:0.001,loss2:0.008] dB[loss1:0.033,loss2:0.023] g[loss1:16.924,loss2:16.979]\n",
      ">423, dA[loss1:0.002,loss2:0.006] dB[loss1:0.003,loss2:0.014] g[loss1:16.921,loss2:17.107]\n",
      ">424, dA[loss1:0.003,loss2:0.003] dB[loss1:0.012,loss2:0.016] g[loss1:17.209,loss2:17.175]\n",
      ">425, dA[loss1:0.003,loss2:0.013] dB[loss1:0.004,loss2:0.041] g[loss1:16.271,loss2:16.806]\n",
      ">426, dA[loss1:0.002,loss2:0.005] dB[loss1:0.006,loss2:0.017] g[loss1:15.706,loss2:16.325]\n",
      ">427, dA[loss1:0.002,loss2:0.005] dB[loss1:0.005,loss2:0.002] g[loss1:16.040,loss2:16.707]\n",
      ">428, dA[loss1:0.002,loss2:0.002] dB[loss1:0.006,loss2:0.030] g[loss1:16.461,loss2:16.580]\n",
      ">429, dA[loss1:0.002,loss2:0.010] dB[loss1:0.012,loss2:0.020] g[loss1:15.296,loss2:15.878]\n",
      ">430, dA[loss1:0.003,loss2:0.006] dB[loss1:0.006,loss2:0.030] g[loss1:16.308,loss2:16.528]\n",
      ">431, dA[loss1:0.001,loss2:0.003] dB[loss1:0.008,loss2:0.028] g[loss1:16.761,loss2:16.865]\n",
      ">432, dA[loss1:0.002,loss2:0.004] dB[loss1:0.012,loss2:0.019] g[loss1:16.180,loss2:16.433]\n",
      ">433, dA[loss1:0.004,loss2:0.003] dB[loss1:0.005,loss2:0.042] g[loss1:16.169,loss2:16.458]\n",
      ">434, dA[loss1:0.003,loss2:0.002] dB[loss1:0.007,loss2:0.010] g[loss1:16.090,loss2:16.413]\n",
      ">435, dA[loss1:0.002,loss2:0.010] dB[loss1:0.007,loss2:0.007] g[loss1:15.808,loss2:16.067]\n",
      ">436, dA[loss1:0.001,loss2:0.022] dB[loss1:0.005,loss2:0.060] g[loss1:16.207,loss2:16.473]\n",
      ">437, dA[loss1:0.004,loss2:0.007] dB[loss1:0.013,loss2:0.039] g[loss1:17.054,loss2:17.063]\n",
      ">438, dA[loss1:0.004,loss2:0.005] dB[loss1:0.009,loss2:0.006] g[loss1:15.993,loss2:16.350]\n",
      ">439, dA[loss1:0.002,loss2:0.011] dB[loss1:0.010,loss2:0.013] g[loss1:17.292,loss2:17.569]\n",
      ">440, dA[loss1:0.004,loss2:0.010] dB[loss1:0.008,loss2:0.050] g[loss1:16.426,loss2:17.395]\n",
      ">441, dA[loss1:0.004,loss2:0.005] dB[loss1:0.022,loss2:0.016] g[loss1:17.427,loss2:17.173]\n",
      ">442, dA[loss1:0.004,loss2:0.003] dB[loss1:0.018,loss2:0.018] g[loss1:16.365,loss2:16.534]\n",
      ">443, dA[loss1:0.001,loss2:0.009] dB[loss1:0.011,loss2:0.016] g[loss1:16.392,loss2:16.614]\n",
      ">444, dA[loss1:0.003,loss2:0.009] dB[loss1:0.007,loss2:0.005] g[loss1:16.820,loss2:16.780]\n",
      ">445, dA[loss1:0.003,loss2:0.003] dB[loss1:0.005,loss2:0.006] g[loss1:16.035,loss2:16.360]\n",
      ">446, dA[loss1:0.004,loss2:0.005] dB[loss1:0.005,loss2:0.011] g[loss1:15.147,loss2:15.725]\n",
      ">447, dA[loss1:0.004,loss2:0.006] dB[loss1:0.005,loss2:0.005] g[loss1:15.081,loss2:15.876]\n",
      ">448, dA[loss1:0.003,loss2:0.012] dB[loss1:0.004,loss2:0.009] g[loss1:15.852,loss2:16.383]\n",
      ">449, dA[loss1:0.001,loss2:0.007] dB[loss1:0.006,loss2:0.039] g[loss1:17.104,loss2:17.265]\n",
      ">450, dA[loss1:0.002,loss2:0.003] dB[loss1:0.003,loss2:0.010] g[loss1:16.636,loss2:17.527]\n",
      ">451, dA[loss1:0.002,loss2:0.003] dB[loss1:0.014,loss2:0.010] g[loss1:16.098,loss2:16.374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">452, dA[loss1:0.004,loss2:0.003] dB[loss1:0.004,loss2:0.004] g[loss1:14.986,loss2:15.811]\n",
      ">453, dA[loss1:0.002,loss2:0.003] dB[loss1:0.008,loss2:0.005] g[loss1:16.380,loss2:16.535]\n",
      ">454, dA[loss1:0.001,loss2:0.005] dB[loss1:0.005,loss2:0.005] g[loss1:17.050,loss2:17.016]\n",
      ">455, dA[loss1:0.003,loss2:0.002] dB[loss1:0.004,loss2:0.003] g[loss1:15.798,loss2:17.064]\n",
      ">456, dA[loss1:0.003,loss2:0.004] dB[loss1:0.004,loss2:0.030] g[loss1:14.579,loss2:15.473]\n",
      ">457, dA[loss1:0.003,loss2:0.008] dB[loss1:0.008,loss2:0.022] g[loss1:16.973,loss2:16.911]\n",
      ">458, dA[loss1:0.001,loss2:0.015] dB[loss1:0.006,loss2:0.015] g[loss1:16.926,loss2:17.371]\n",
      ">459, dA[loss1:0.002,loss2:0.018] dB[loss1:0.004,loss2:0.022] g[loss1:14.926,loss2:15.907]\n",
      ">460, dA[loss1:0.007,loss2:0.010] dB[loss1:0.007,loss2:0.008] g[loss1:16.913,loss2:16.952]\n",
      ">461, dA[loss1:0.008,loss2:0.004] dB[loss1:0.010,loss2:0.013] g[loss1:15.827,loss2:16.209]\n",
      ">462, dA[loss1:0.001,loss2:0.016] dB[loss1:0.013,loss2:0.005] g[loss1:17.158,loss2:17.378]\n",
      ">463, dA[loss1:0.004,loss2:0.014] dB[loss1:0.005,loss2:0.005] g[loss1:16.102,loss2:16.458]\n",
      ">464, dA[loss1:0.004,loss2:0.006] dB[loss1:0.005,loss2:0.029] g[loss1:15.867,loss2:16.304]\n",
      ">465, dA[loss1:0.005,loss2:0.004] dB[loss1:0.006,loss2:0.010] g[loss1:17.383,loss2:16.766]\n",
      ">466, dA[loss1:0.003,loss2:0.007] dB[loss1:0.009,loss2:0.016] g[loss1:15.467,loss2:15.696]\n",
      ">467, dA[loss1:0.005,loss2:0.007] dB[loss1:0.009,loss2:0.007] g[loss1:16.407,loss2:16.322]\n",
      ">468, dA[loss1:0.001,loss2:0.005] dB[loss1:0.004,loss2:0.008] g[loss1:16.130,loss2:16.163]\n",
      ">469, dA[loss1:0.003,loss2:0.006] dB[loss1:0.003,loss2:0.012] g[loss1:14.492,loss2:15.270]\n",
      ">470, dA[loss1:0.002,loss2:0.005] dB[loss1:0.004,loss2:0.009] g[loss1:16.138,loss2:16.328]\n",
      ">471, dA[loss1:0.024,loss2:0.048] dB[loss1:0.004,loss2:0.004] g[loss1:16.212,loss2:16.789]\n",
      ">472, dA[loss1:0.008,loss2:0.020] dB[loss1:0.005,loss2:0.018] g[loss1:15.808,loss2:16.523]\n",
      ">473, dA[loss1:0.004,loss2:0.005] dB[loss1:0.010,loss2:0.006] g[loss1:16.198,loss2:16.528]\n",
      ">474, dA[loss1:0.001,loss2:0.003] dB[loss1:0.007,loss2:0.020] g[loss1:16.813,loss2:16.650]\n",
      ">475, dA[loss1:0.006,loss2:0.008] dB[loss1:0.006,loss2:0.005] g[loss1:15.616,loss2:16.582]\n",
      ">476, dA[loss1:0.009,loss2:0.006] dB[loss1:0.004,loss2:0.018] g[loss1:16.307,loss2:16.961]\n",
      ">477, dA[loss1:0.007,loss2:0.044] dB[loss1:0.005,loss2:0.017] g[loss1:16.923,loss2:17.679]\n",
      ">478, dA[loss1:0.010,loss2:0.010] dB[loss1:0.007,loss2:0.039] g[loss1:17.086,loss2:17.542]\n",
      ">479, dA[loss1:0.016,loss2:0.014] dB[loss1:0.008,loss2:0.015] g[loss1:16.929,loss2:17.353]\n",
      ">480, dA[loss1:0.002,loss2:0.011] dB[loss1:0.006,loss2:0.012] g[loss1:16.558,loss2:17.097]\n",
      ">481, dA[loss1:0.002,loss2:0.012] dB[loss1:0.005,loss2:0.043] g[loss1:15.727,loss2:16.462]\n",
      ">482, dA[loss1:0.002,loss2:0.014] dB[loss1:0.018,loss2:0.152] g[loss1:16.933,loss2:17.180]\n",
      ">483, dA[loss1:0.002,loss2:0.010] dB[loss1:0.048,loss2:0.142] g[loss1:15.678,loss2:16.725]\n",
      ">484, dA[loss1:0.001,loss2:0.007] dB[loss1:0.031,loss2:0.010] g[loss1:16.396,loss2:17.044]\n",
      ">485, dA[loss1:0.001,loss2:0.006] dB[loss1:0.031,loss2:0.010] g[loss1:16.804,loss2:17.004]\n",
      ">486, dA[loss1:0.001,loss2:0.017] dB[loss1:0.015,loss2:0.006] g[loss1:16.541,loss2:17.041]\n",
      ">487, dA[loss1:0.006,loss2:0.009] dB[loss1:0.007,loss2:0.010] g[loss1:16.595,loss2:17.290]\n",
      ">488, dA[loss1:0.003,loss2:0.012] dB[loss1:0.008,loss2:0.033] g[loss1:16.859,loss2:17.380]\n",
      ">489, dA[loss1:0.004,loss2:0.008] dB[loss1:0.011,loss2:0.012] g[loss1:15.860,loss2:16.553]\n",
      ">490, dA[loss1:0.003,loss2:0.007] dB[loss1:0.003,loss2:0.006] g[loss1:16.476,loss2:16.864]\n",
      ">491, dA[loss1:0.005,loss2:0.005] dB[loss1:0.008,loss2:0.006] g[loss1:16.324,loss2:16.833]\n",
      ">492, dA[loss1:0.002,loss2:0.008] dB[loss1:0.006,loss2:0.013] g[loss1:14.986,loss2:16.136]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# load a dataset as a list of two numpy arrays\n",
    "trainA, trainB,testA, testB = load_imgs()\n",
    "print(trainA.shape)\n",
    "print(trainB.shape)\n",
    "print(testB.shape)\n",
    "dataset = (trainA, trainB)\n",
    "\n",
    "# input shape\n",
    "image_shape = (trainA.shape[1],trainA.shape[2],1)\n",
    "# generator: A -> B\n",
    "g_model_AtoB = define_generator(image_shape)\n",
    "# generator: B -> A\n",
    "g_model_BtoA = define_generator(image_shape)\n",
    "# discriminator: A -> [real/fake]\n",
    "d_model_A = define_discriminator(image_shape)\n",
    "# discriminator: B -> [real/fake]\n",
    "d_model_B = define_discriminator(image_shape)\n",
    "g_model_AtoB.summary()\n",
    "g_model_BtoA.summary()\n",
    "d_model_A.summary()\n",
    "d_model_B.summary()\n",
    "# composite: A -> B -> [real/fake, A]\n",
    "c_model_AtoB = define_composite_model(g_model_AtoB, d_model_B, g_model_BtoA, image_shape)\n",
    "# composite: B -> A -> [real/fake, B]\n",
    "c_model_BtoA = define_composite_model(g_model_BtoA, d_model_A, g_model_AtoB, image_shape)\n",
    "# train models\n",
    "train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "from keras.models import load_model\n",
    "model = load_model('saved_model/p2hGenAB_2_150.h5',custom_objects={'InstanceNormalization':InstanceNormalization})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter a sentence: good morning\n"
     ]
    }
   ],
   "source": [
    "from text import str_to_image\n",
    "response = input(\"Please enter a sentence: \")\n",
    "im = str_to_image(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 48, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "from keras.models import load_model\n",
    "model = load_model('saved_model/p2hGenAB_2_357.h5',custom_objects={'InstanceNormalization':InstanceNormalization})\n",
    "#model.saveAtoB(im, 'test_arch1.png')\n",
    "X = model.predict(im)\n",
    "#X = np.asarray(X).astype('float32') / 255\n",
    "print(X.shape)\n",
    "# This part only for show the image on the screen, you can delete it if you want\n",
    "#pathA = 'test_arch1.png'\n",
    "#img = cv2.imread(pathA)\n",
    "#cv2.imshow('image', img)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.asarray(X).astype('float32') / 255\n",
    "cv2.imshow('image',X[0])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'datasets2/words/trainA/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-8554c05ab7d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load a dataset as a list of two numpy arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrainA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtestA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_imgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-77-1a2d3fe6dfcf>\u001b[0m in \u001b[0;36mload_imgs\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprinted_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'datasets2/words/trainA/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprinted_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprinted_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m       \u001b[1;31m#load the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m       \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprinted_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'datasets2/words/trainA/'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
